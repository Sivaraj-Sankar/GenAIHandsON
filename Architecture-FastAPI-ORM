Swagger UI
🚀 Explore your API endpoints (GET, POST, etc.)
🧪 Test endpoints directly from the browser
📝 See request/response formats
✅ Validate your OpenAPI schema
📚 Generate API documentation automatically
FastAPI generates Swagger UI automatically from your code using Python type hints and decorators (@app.get(), @app.post(), etc.).


Server 
🖥️ Starts your app
📡 Listens on a port (e.g., 8000)
📥 Accepts HTTP requests (like GET, POST)
🧠 Passes those requests to your FastAPI functions
📤 Sends back responses (like JSON)
1.uvicorn is an ASGI web server for Python. It is commonly used with FastAPI.
2.It understands the ASGI[Asynchronous Server Gateway Interface] interface (like WSGI, but async).
3.FastAPI is ASGI-native, and Uvicorn is one of the best ASGI servers

1.gunicorn - Most popular WSGI server
2.uwsgi - Feature-rich, production-grade
3.mod_wsgi - Used with Apache HTTP Server.

ASGI ensures the kitchen and delivery person speak the same language, especially for real-time orders (WebSockets) or multiple orders at once (async)
Term	Meaning
ASGI	Async Server Gateway Interface — defines how async Python servers/apps talk
Purpose	Enables modern async apps with HTTP/2, WebSockets, long-lived requests
Example	FastAPI uses ASGI; Uvicorn is an ASGI server


Fast API

fastapi_project/
│
├── app/
│   ├── __init__.py
│   ├── main.py                  # Entry point of the application
│   ├── config.py                # Configuration settings (can use Pydantic BaseSettings)
│   ├── dependencies/            # Reusable dependencies
│   │   ├── __init__.py
│   │   └── auth.py              # Auth-related dependencies
│   ├── models/                  # ORM models (e.g., SQLAlchemy)
│   │   ├── __init__.py
│   │   └── user.py
│   ├── schemas/                 # Pydantic schemas for request/response validation
│   │   ├── __init__.py
│   │   └── user.py
│   ├── crud/                    # CRUD logic separated from routes
│   │   ├── __init__.py
│   │   └── user.py
│   ├── services/                # Business logic or integrations
│   │   ├── __init__.py
│   │   └── user_service.py
│   ├── api/                     # Route files
│   │   ├── __init__.py
│   │   ├── deps.py              # Dependencies specific to routes
│   │   └── v1/                  # Versioned APIs
│   │       ├── __init__.py
│   │       └── user.py
│   ├── db/                      # Database utilities
│   │   ├── __init__.py
│   │   ├── base.py              # Base class for all models
│   │   └── session.py           # DB session management
│   ├── core/                    # Core functionality (e.g., JWT, hashing)
│   │   ├── __init__.py
│   │   ├── security.py
│   │   └── hashing.py
│   ├── middleware/              # Custom middlewares
│   │   ├── __init__.py
│   │   └── logging.py
│   └── utils/                   # Utility functions
│       ├── __init__.py
│       └── helpers.py
│
├── tests/                       # Test suite
│   ├── __init__.py
│   └── test_user.py
│
├── .env                         # Environment variables
├── alembic/                     # Alembic migrations (if using SQLAlchemy)
│   └── ...
├── alembic.ini
├── requirements.txt             # Dependencies
├── README.md
├── Dockerfile                   # Docker configuration
├── docker-compose.yml
└── pyproject.toml               # Optional - for Poetry projects

ORM Model
An ORM model refers to an Object-Relational Mapping (ORM) approach where you interact with a database using objects in your programming language — instead of writing raw SQL queries.

main.py
from fastapi import FastAPI
from app.api.v1 import user

app = FastAPI(title="My FastAPI Project")

# Register routers
app.include_router(user.router, prefix="/api/v1/users", tags=["Users"])



Use SQLAlchemy or Tortoise ORM for database interaction.
Use Pydantic for request and response validation.
Version your API with folders like /api/v1/.
Use Alembic for database migrations.
Use dotenv to manage secrets and configurations.

MVP Architecture 
----------------
MVP Architecture stands for Model-View-Presenter. It is a design pattern commonly used in software development, especially in GUI applications like web and mobile apps
MVP separates the application logic into three interconnected components to improve code maintainability, testability, and separation of concerns.


Components of MVP
Model
What it is: Represents the data layer and business logic
Fetching data (from database, API, etc.)
Performing business operations

Software Architecture and Design Patterns[Specifically under Application Architecture / UI Architecture strategies.]
Software Architecture	High-level structure of a system, defining major components and their interactions.	MVC, MVT, MVP, Clean Architecture
Software Design Patterns	Reusable solutions to common problems in software design.	Singleton, Factory, Repository, etc.
Application Layer	Defines how user requests are processed (Controllers, Views, APIs).	MVC Controller, FastAPI routes
Domain Layer / Business Logic	Encapsulates core logic/rules of the application.	Services, Use Cases, Interactors
Data Access Layer	Responsible for database access and persistence.	Models, ORM, Repositories
Presentation Layer	User interface or API output generation.	HTML Templates, JSON responses


+-------------------------------------------------------------+
|                    Presentation Layer (UI/API)              |
|-------------------------------------------------------------|
|  - HTML/CSS/JS (Web UI)                                     |
|  - React, Vue, Angular (Frontend)                           |
|  - JSON/HTML Templates (Django Templates)                   |
|  - REST APIs / FastAPI Routes                               |
|                                                             |
|  🌐 [ MVT (Templates), MVC (View), MVP (View), Routers ]    |
+-------------------------------------------------------------+
|                    Application / Logic Layer                |
|-------------------------------------------------------------|
|  - Controllers / Views / Presenters                         |
|  - Business Logic / Services                                |
|  - Validation (Pydantic, Forms)                             |
|                                                             |
|  🧠 [ MVC (Controller), MVT (View), MVP (Presenter),         |
|       Clean Architecture (Use Cases/Services) ]             |
+-------------------------------------------------------------+
|                    Domain / Model Layer                     |
|-------------------------------------------------------------|
|  - Database Models (ORMs like Django Models, SQLAlchemy)    |
|  - Domain Logic / Rules                                     |
|                                                             |
|  🧩 [ MVC/MVT/MVP (Model), Clean Architecture (Entities) ]  |
+-------------------------------------------------------------+
|                    Data Access / Infrastructure             |
|-------------------------------------------------------------|
|  - Database Drivers / Repositories                          |
|  - External Services / APIs                                 |
|                                                             |
|  🗃️ [ Clean Architecture (Repository), ORM, etc. ]          |
+-------------------------------------------------------------+
|                        Configuration                        |
|-------------------------------------------------------------|
|  - Settings, Env Vars, Middleware, Security Config          |
|                                                             |
|  ⚙️ [ Shared across layers ]                                |
+-------------------------------------------------------------+
🔍 Explanation by Architecture:
Architecture	Fits In	Usage in Practice
MVC	UI, Controller, Model	Web apps, backend APIs, frameworks like Laravel
MVT (Django)	Templates, Views, Models	Django-specific apps
MVP	UI apps with heavy logic separation	Mobile apps, desktop apps
Clean Architecture	All layers, well-separated	Modern scalable apps (FastAPI, Flask, etc.)


Microservices 
-------------
Microservice Architecture is a software architectural style where an application is composed of small, independent services that communicate over well-defined APIs. 
Each microservice focuses on a specific business capability, can be developed, deployed, and scaled independently, and often has its own database

📦 Tools Commonly Used in Microservice Architecture
Category	Tools/Technologies
API Gateway	Kong, NGINX, AWS API Gateway
Service Discovery	Consul, Eureka, Etcd
Messaging	RabbitMQ, Apache Kafka
Config Management	Spring Cloud Config, Consul
Logging & Monitoring	ELK Stack, Prometheus, Grafana
Containers	Docker
Orchestration	Kubernetes
CI/CD	Jenkins, GitHub Actions, GitLab CI


What Are Microservices?
Microservices are:
Small, focused modules
Loosely coupled
Autonomously deployable
Built around business domains
Communicate via HTTP/REST, gRPC, message queues, etc.

📋 Key Characteristics of Microservice Architecture
Feature	Description
Modularity	Each service implements a specific business function
Independence	Services are self-contained and can be deployed separately
Technology diversity	Each microservice can use different languages/frameworks
Decentralized data	Each service can manage its own database
Resilience	Failure in one service does not crash the whole system
Scalability	Services can be scaled independently
Continuous delivery	Easier CI/CD due to small scope

🧱 Components of Microservice Architecture
Here’s a breakdown of the core components commonly found in microservices:

1. API Gateway
Entry point for all clients
Handles routing, authentication, and rate limiting
Example: Kong, NGINX, AWS API Gateway

2. Service Registry and Discovery
Keeps track of service instances and enables dynamic service discovery
Example: Eureka, Consul, Etcd

3. Microservices
Independently deployable business units
Often deployed in containers
Communicate via REST/gRPC/message brokers

4. Database per Service
Each service manages its own schema and data
Prevents tight coupling at the database level

5. Inter-Service Communication
REST APIs (HTTP)
gRPC
Message brokers (RabbitMQ, Kafka)

6. Centralized Configuration Management
Externalized configuration for all services
Tools: Spring Cloud Config, Consul, Vault

7. Distributed Logging & Tracing
Monitor and debug across services
Tools: ELK Stack, Jaeger, Zipkin

8. Monitoring
Health checks, metrics, alerting
Tools: Prometheus, Grafana, Datadog

9. Security
Authentication & Authorization (e.g., OAuth2, JWT)
Service-to-service encryption (TLS/mTLS)

10. Containerization & Orchestration
Services are packaged in containers and managed with:
Docker
Kubernetes

🧩 Examples of Microservices in an E-commerce App
Microservice	Responsibilities
User Service	Handles user registration/authentication
Product Service	Manages product catalog
Order Service	Handles orders and transactions
Payment Service	Manages payment processing
Inventory Service	Tracks stock levels
Notification Service	Sends emails, SMS, alerts
Shipping Service	Calculates and tracks delivery


Reverse Proxy 
🧰 Reverse Proxy Use Cases
Use Case	Example / Benefit
Load Balancing	Distribute requests across multiple servers
SSL Termination	Handle HTTPS encryption centrally
Caching	Store and serve frequently requested content
Security & DDoS Protection	Hide backend IPs, rate limiting, IP filtering
URL Routing	Forward requests to different apps by path
Authentication Gateway	Central login/token verification

💡 Real Tools That Act as Reverse Proxies
Tool	Description
NGINX	Most common reverse proxy server
HAProxy	High-performance load balancer
Apache	Can be configured as a reverse proxy
Traefik	Dynamic reverse proxy for microservices
Cloudflare	Acts as a global reverse proxy (CDN + protection)


✅ Example (NGINX Reverse Proxy for FastAPI)
Imagine your FastAPI app runs at http://localhost:8000. NGINX can reverse proxy this:
nginx
Copy
Edit
server {
    listen 80;

    location / {
        proxy_pass http://localhost:8000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
    }
}
When a browser hits http://yourdomain.com, it talks to NGINX, which forwards it to FastAPI running behind the scenes.

✅ Summary
A reverse proxy is like a smart middleman that sits in front of your backend services.
Clients only talk to the reverse proxy — it hides, protects, and optimizes access to backend servers.
Common for load balancing, routing, SSL, and security.

[Inputs: Text | Image | Audio | Video]
        ↓
1. **Modality-Specific Encoders**
   - Text → Token Embedding (LLM-style)
   - Image → CNN/Vision Transformer (ViT)
   - Audio → Spectrogram → CNN/RNN
   - Video → Frames → Vision + Time encoders
        ↓
2. **Unified Representation Layer**
   - All modalities projected into a common embedding space
        ↓
3. **Cross-Modal Attention / Fusion Layers**
   - Learn interactions between text ↔ image ↔ audio
        ↓
4. **Decoder or Output Layer**
   - Text generation, classification, retrieval, etc.


Feature	LLM	Multimodal Model
Input Types	Text only	Text, images, audio, video, etc.
Modality Encoders	Text tokenizer + embeddings	Separate encoders per modality
Core Processing	Transformer (text only)	Cross-modal transformer / fusion layers
Use Cases	Chatbots, writing, coding, etc.	Image captioning, VQA, AI assistants
Example Models	GPT-3, GPT-4, LLaMA, Claude	GPT-4o, Gemini, CLIP, Flamingo

         +-----------------------------+
         |      Multimodal Inputs      |
         |  (Text, Image, Audio, etc.) |
         +-----------------------------+
                       ↓
     +-------------------------------------+
     | 1. Modality-Specific Encoders       |
     | - Text → Token Embedding (LLM)      |
     | - Image → CNN / ViT Encoder         |
     | - Audio → Spectrogram + CNN / RNN   |
     | - Video → Vision + Temporal Module  |
     +-------------------------------------+
                       ↓
     +--------------------------------------+
     | 2. Unified Multimodal Representation |
     | - All modalities mapped to same space|
     | - Cross-modal attention / fusion     |
     +--------------------------------------+
                       ↓
     +--------------------------+
     | 3. Task Decoder Layer    |
     | - Text → LLM-style decoder       |
     | - Image → Image generator (e.g. VAE, Diffusion) |
     | - Audio → Text-to-speech decoder |
     +--------------------------+
                       ↓
         +-----------------------------+
         |     Multimodal Outputs      |
         | (Text, Image, Audio, Action)|
         +-----------------------------+

Modality	Encoder Examples	Output Decoders
Text	BERT, GPT, LLaMA (tokenizer + transformer)	LLM decoder
Image	ViT, ResNet, CLIP-Image	VAE, Stable Diffusion
Audio	Wav2Vec, Whisper	Tacotron, WaveNet
Video	TimeSformer, SlowFast	VideoGAN, Motion transformers

Layer	Description
Modality-Specific Encoders	Convert raw data (text/image/audio) into embeddings
Fusion Layer	Align and combine multiple modalities into a shared space
Cross-Modal Attention	Learn interactions between, say, text and image
Unified Embedding	A single representation that holds multimodal meaning
Task-Specific Decoders	Generate appropriate output (text/image/audio/action)


https://www.youtube.com/watch?v=helW1httyO8
This video tutorial from CVPR 2022 delves into multimodal machine learning technologies, behaviors, and signals. It provides a visual and auditory learning experience, complementing the textual resources.
https://www.v7labs.com/blog/multimodal-deep-learning-guide
This article offers a comprehensive overview of multimodal deep learning, including its definition, challenges, and various applications. It's a great starting point for understanding the broader context and significance of multimodal models.
https://github.com/dsaidgovsg/multimodal-learning-hands-on-tutorial
This practical tutorial guides you through building a multimodal classifier that processes both text and images using Transformer models. It's ideal for those looking to apply multimodal learning techniques in real-world scenarios.
https://arxiv.org/abs/2405.17927
This research paper categorizes and analyzes four prevalent multimodal model architectural patterns, offering insights into their methodologies for integrating multimodal inputs. It's a valuable resource for understanding the evolution and design choices in multimodal architectures.
arXiv
+1
arXiv
+1
https://slds-lmu.github.io/seminar_multimodal_dl/c02-00-multimodal.html
This chapter provides an in-depth exploration of multimodal learning, focusing on integrating different input modalities like images and text. It discusses various architectures and fusion techniques used in multimodal models.

            +--------------------+
            |  User Input (Goal) |
            +--------------------+
                      ↓
          +-------------------------+
          | 1. Perception Layer     | ← Interpret input context
          | (LLM, tokenizer)        |
          +-------------------------+
                      ↓
          +-------------------------+
          | 2. Memory / Context     | ← Stores past state, history
          | (short-term / long-term)|
          +-------------------------+
                      ↓
          +-------------------------+
          | 3. Planner Module       | ← Plans sequence of steps
          | (LLM + reasoning prompt)|
          +-------------------------+
                      ↓
          +-------------------------+
          | 4. Tool Selector        | ← Chooses APIs/tools/functions
          | (via function calling) |
          +-------------------------+
                      ↓
         +------------------------------------+
         | 5. Tool Execution / Environment    | ← Calls external tools |
         | (e.g. web, DB, calculator, Python) |
         +------------------------------------+
                      ↓
          +-------------------------+
          | 6. Result Interpreter   | ← Evaluates tool output
          +-------------------------+
                      ↓
          +-------------------------+
          | 7. Action / Response    | ← Final answer or next action
          +-------------------------+

Component	Description
LLM	Core reasoning engine (e.g., GPT-4, Claude, Gemini)
Memory	Stores history, facts, task state
Planner	Uses chain-of-thought or scratchpad prompting to decide what to do next
Tool Use	Executes external actions (e.g., search, code, math, API calls)
Executor	Actually runs the tool or code (e.g., Python REPL, web scraper)
Environment	Context where the agent acts (e.g., browser, file system, game)
Reflection / Critic	Optional step for self-evaluation and correction

Framework / System	Description
LangChain Agents	Tool-using LLMs with planning and execution
AutoGPT / BabyAGI	Autonomous LLM agents with looping goals
ReAct Framework	Combines reasoning and action into prompts
LangGraph (by LangChain)	Graph-based agent planning architecture
OpenAI Function Calling + Tools	Call external tools via LLM reasoning
Voyager (Minecraft agent)	LLM-based lifelong learning agent in a virtual world

LLM Agentic Architecture turns a static language model into a dynamic, goal-oriented system capable of:
Reasoning over complex tasks
Calling tools/APIs
Maintaining memory
Interacting with environments
It’s a foundational step toward AI that can autonomously solve problems, not just generate text.


https://cohere.com/blog/embed-4


