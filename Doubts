Agentic RAG 
1) Router includes capability to request clarification for ambiguous queries
2) How pass the prompt with query with Agent - In Every call or Single Call
3) How to Manage the Memory of the Agent 
4) How to Retrieve the Response for Agentic RAG - Either by Reterival Strategy or through the Agentic CoT Approach with memory management 
5) Chunking with Metadata - How much have to give in chunk 
6) How to Manage the Session for Agent 
7) Preprocessing the Data Properly with Metadata 
8) Vector Database that support the Metadata 
9) Query should rewrite based on the prompt 
10) Summarize Agentic RAG - QA Agentic RAG 
11) Referencing the Source 
12) MCP Protocol
13) Connectors for Multiple Data Sources
14) Testing the Agentic RAG 
15) Experimenting the Agentic RAG 
16) Tool Description - for Agentic RAG 
17) Error Handling and Fallback Strategies 
18) Pydantic Object to check we receiving the Structured output from LLM 
19) How to Use the Structured Output 
20) Data Pipeline 
21) Handle edge cases explicitly
22) Actions if needed for Agents to make decisions
23) Guardrails, 
24) Responsible AI 
25) Monitoring the AI Agent 
24) Evaluating the AI Agent and Decision of AI Agent 
25) Logging 

26) Agent 1  - Rewrite Query with Selective Retrieval    Agent 2 - Reflect --- Agent 3 -- Prompt with [Respective Ouput] + [Respective Retrieval from LLM ] - Multiple Calls or Single Calls

27) How to Evaluate the Retrieved Document 


Complex PDF RAG Pipeline 
------------------------
1) Dropping relevant graphics from your context
2) Gemini 2.5 with a multimodal Embedding model like Cohere's latest Embed v4
3) Unlock vision RAG and avoid image-to-markdown conversion.
4) Combines Gemini Flash 2.5 (vision LLM) with Cohere Embed v4 (retrieval).
5) Directly retrieves & understands complex images (slides, charts, graphs, infographics).
6) Cohere Supports processing of documents up to 128,000 tokens, approximately equivalent to 200 pages, making it suitable for large-scale document analysis - adjustable embedding dimensions (e.g., 256, 512, 1024, 1536)

Cost Effective 
---------------
LlamaParse - Cost=300×0.0015=0.45 USD
Cohere     - Cost=1.5×0.47=0.705 USD


General Architecture
Build modular components
Implement robust error handling
Consider scaling requirements
Plan for monitoring and evaluation


28) how Multi Agent are working so far I created in LangGraph and CrewAI - is it waiting for other agents to complete the work , are passing the task sequentially 
    In Letta - the Multi Agent Concept is different 

29) How to Pass the Tools name to the OpenAI Function Call 
       Function Definition - Pydantic Object to create the Function Definition
    How to create the Actual Python function tool --> whith doc string to --> for LLM to understand 

30) How Manager Agent calls the other agents, by reasoning - Check the course learned crewAI, AutoGen, etc
          giving other agents as tool or how ?

31) How Async works with    - concurrently run all three agents - parallely 
async def main():
    msg = input( )
    orchestrator_output = await Runner.run(manager_agent,msg)


32) Prompt Should be build up from the layers and layers of input data 
33) Evaluation - getmaxim.ai has built a very comprehensive agent simulation and evals platform. 
34) Evaluation - Wayfound.ai 
35) Evaluation - Noveum.ai 
36) Evaluation - Instructor - https://github.com/instructor-ai/instructor - MIT License 
                 (If you’re importing an LLM API SDK, use Instructor; if you’re importing Huggingface for a self-hosted model, use Outlines.)

37) Applied LLM - https://applied-llms.org/

38) Evaluation - https://noveum.ai/en

38) MegaPrompt - Approach 
39) The specificity of task-oriented prompts means they aren't suitable for general, open-ended conversations.
    https://www.godaddy.com/resources/news/llm-from-the-trenches-10-lessons-learned-operationalizing-models-at-godaddy#h-1-sometimes-one-prompt-isn-t-enough

40) Important Techniques - https://www.godaddy.com/resources/news/llm-from-the-trenches-10-lessons-learned-operationalizing-models-at-godaddy#h-1-sometimes-one-prompt-isn-t-enough

--------------------------------------------------------------------
API Integration
----------------
Event Web API 
HTTP Web API's 

API Scaling
-----------
How to Scale API Performance in a High-Load System and Avoided CPU Overload
API - Plays a Role of Gateway that manages incoming requests from all entities 
Each API has a limited number of requests it can process 
When API is overloaded, your Whole System essentially stops, as it can't output any results without 
processing requests first 

USER (Millions of users)
         ↓
      Internet
         ↓
    [Load Balancer]
         ↓
 ┌─────────────┬─────────────┬─────────────┐
 │             │             │             │
[Backend Server 1] [Backend Server 2] [Backend Server 3] ... (Auto-scaled instances)
 (Async API App)    (Async API App)    (Async API App)
         ↓             ↓               ↓
 ┌─────────────┬─────────────┬─────────────┐
 │             │             │             │
[Cache Layer] [Database (Read Replica)] [External Services]
 (Redis Memcachedetc.)  (Async ORM, Pooling)      (if needed)

Redis / Memcached for caching frequent results
CDN (like Cloudflare) for caching static API responses

1.Scaling a highly loaded API that processes resource-intensive requests, 
2.Also show how to calculate the future load on the system and choose the most suitable instances 
  for scaling, as well as our scaling Scheme and debugging activities.
2. Look for a balance system performace and required computing resources.
Vertical Scaling[up or down] - more VM's  vs Horizontal Scaling [in or out] - several endpoints
--------------------------------------
Horizontal Scaling - enhance your system with additional physical computing power. create Sharded database 
                     deploy more nodes. 


What type of scaling should you choose for your system?
How can you calculate the future load on your system?
How can you choose instances for scaling?
How can you design and debug a cloud scaling system?

Eg:Each request takes between 30 seconds and one minute and up to 20% of server CPU power.
An excessive number of requests should not cause the machine to freeze and make it inoperable.

Be able to process up to five million requests per day
Withstand a heavy bandwidth load in order to communicate with third-party services

REST API
SQS
Lambda
DynamoDB

Application Load Balancer
EC2
DynamoDB

Application Load Balancer
EC2
DynamoDB

4 CPUs, 8 GB RAM - instance can process 60 to 120 requests per minute, or 2 to 3 requests per second, before crashing.


Wrote a simple application prototype with unchangeable logic.
Launched the easiest and cheapest instance on AWS and loaded it until it failed.
Saw how many queries this instance completed and which criteria made it fail.
Launched a more powerful instance and tried to crash it with our prototype.

We used JMeter to find the maximum load on AWS instances until we found the most suitable ratio of instance parameters and time to crash

1.Failure of one API request can affect other requests.
2.When one request overloaded a browser, it couldn’t process subsequent requests. To fix this, we isolated each process and limited the load by creating internal requests and a request queue for each server.
3.The first step was to create a worker that would run our program independently so that in case of errors, we would lose only one request instead of all operations. 
4.This worker takes one task at a time from the queue after completing the previous one. In our case, the CPU load per worker was 7%.
5.Next, we increased the number of workers until the CPU was 80% loaded. This way, we got an isolated process with a predictable load and created a number of parallel tasks for the instance to process.
6.Our API keeps the connection active until it gets a response. Under a heavy load, it took our system three to five minutes to respond, and during this time the application load balancer ended the connection. We increased the maximum connection time for the API to three to four minutes. During this time, we can create a new instance if needed.  
7.However, this method of scaling has several disadvantages you need to be aware of. The request queue inside the instance helps to manage API performance, but it shouldn’t accumulate more requests than the instance can process within three minutes. Since the API connection lasts for three to four minutes, the API won’t get responses to requests that take longer. That’s why we need to launch a new instance during this time.

Developing Robust API's 
-----------------------
1. Designing High-Quality APIs,
KISS - Keep It Simple, Stupid.
2.Use Standard, concrete and shared terms that are familiar to most people 
3.Allow application developers to do things in only one way, rather than offering multiple confusing options.
4.Design the API with the needs of the client in mind
5.Medium Grained Resources - You Should use medium grained, not fine nor coarse. 
  Resources shouldn't be nested more than two level deep 
6. Snake_Case or CamelCase for attributes and parameters. 
7. for using more than one word in URL - spinal-case 
8. Versioning mandatory in the URL at the highest scope (major versions). 
9. You may support at most two versions at the same time (Native apps need a longer cycle)

Collection Resource: /employees
Instance Resources: /employees/11


Django Views
------------
Function-Based Views (FBV)
    ↓
Class-Based Views (CBV)
    ↓
Generic Class-Based Views (GCBV) → Special ready-made
    ↓
ViewSets → For APIs (Django REST Framework)


Interview Question
------------------
1.What is Whitelist - Whitelisting in APIs is a security practice used to control access to an API by explicitly allowing only certain clients, 
                      IP addresses, domains, or applications to use it
This is common for internal APIs or services accessed only from a specific office or server.
IP addresses
API keys or tokens
Domains or referrers
User agents
Applications or client IDs
-Limitations of Whitelisting
IP spoofing (though rare if HTTPS is used) can be a risk if relying only on IP addresses.
Not suitable for mobile apps or dynamic IPs.
Managing large or changing whitelists can become complex

2. How Whitelist Implemented - 
Firewall or API Gateway level (e.g., AWS API Gateway, Apigee, NGINX)
Within application logic (e.g., checking IP or key manually)
Cloud IAM policies (e.g., Google Cloud IAM, AWS IAM roles)

3.Different Whitelisting 
IP Address Whitelisting
API Key Whitelisting - Developer should register for whitelisting 
Domain/Origin Whitelisting
OAuth Client Whitelisting

4.IP Spoofing
IP spoofing occurs when a hacker modifies the packet headers to insert a fake (spoofed) source IP address.
eg. of of the example of attacking[Session Hijacking] - Rare, but spoofing can be used to hijack a TCP session if sequence numbers are predictable.
Authentication mechanisms: Don't rely on IP alone—use tokens, keys, or certificates.


5.Rate Limiting - Only allow approved users to consume API resources, which protects performance
These can be global (per user/IP) or granular (per endpoint, per API key, per method, etc.)
429 Too Many Requests
system keeps track of requests per client, and once a client exceeds their quota, the system can
-Reject the request with an HTTP status (e.g., 429 Too Many Requests)
-Queue the request (in some APIs)
-Temporarily block the client (a "cooldown" or "timeout")
-Apply backoff logic (e.g., wait before retrying)

Rate Limiting Algorithms
 Token Bucket
Tokens are added to a “bucket” at a fixed rate
Each request consumes a token.
If no tokens are left → request is denied.

Leaky Bucket
Similar to token bucket but allows tokens to “leak” at a constant rate.
Smoothens traffic spikes over time.

Fixed Window
Counts requests in a fixed time window (e.g., per minute).
Simple but has boundary issues (spike at end/start of window).

 Sliding Window
Improves on fixed window by using rolling time periods
More accurate in evenly enforcing limits

How to implement the Rate Limit 
API Gateways (e.g., AWS API Gateway, NGINX, Kong)
Backend servers or middleware
Web Application Firewalls (WAF)
CDNs (e.g., Cloudflare)


6.Azure API Management (APIM) [You need a centralized API management layer across different backends
                               You're integrating with Azure services]
Centralized API gateway for managing REST and SOAP APIs
Rate limiting, quotas, throttling via policies
Supports OpenAPI, WSDL, Swagger, and GraphQL (preview)
Backend integration with Azure Functions, App Services, Logic Apps, etc
Built-in analytics, logging, and monitoring
Security via OAuth2, JWT validation, IP filtering, and more
Supports multi-region deployments and versioning

7.Different API 
REST, HTTP, WebSocket
REST, SOAP, GraphQL

8.Authentication - Think of it as a login check.
  -username and password
  -Using Multi-Factor Authentication (MFA)
  -Presenting a valid API key or token
  -Signing in with Google, Azure AD, or GitHub(OAuth/OpenID)


9.Authorization - Authorization is the process of checking what actions an authenticated user is allowed to perform
Think of it as permission checking
  -An API token may only allow read access to data, not write

10.Authentication
Authentication methods:
In Web/API Context
  -Basic Auth
  -OAuth2 / OpenID Connect
  -JWT (JSON Web Tokens)
  -API Keys
  -SAML

11.Oauth ==== -  - - - - - Client redirects user to Authorization Server
App opens browser: https://accounts.google.com/o/oauth2/v2/auth?...
Includes client_id, scope, and redirect_uri
User logs in & approves access
Google shows login + consent screen
User clicks “Allow”
Authorization Server redirects back to Client
Sends an Authorization Code to the app via redirect_uri
Client exchanges Code for Access Token
App sends code + secret to Authorization Server
Server returns an Access Token (and optionally a Refresh Token)
Client uses Access Token to access Resource
App calls the API with the token:
Authorization: Bearer ACCESS_TOKEN

12. Middleware Task in Django
Modify request before view	Add user data, parse headers, attach tokens
Process response after view	Add CORS headers, compress response
Handle exceptions globally	Catch and log errors or show error pages
Control access	Block IPs, enforce authentication
Performance measurement	Log timing or request metrics

13. Central Configuration Hub - central configuration hub - Settings.py
   How should your app behave 
   database setup, installed apps, middleware, templates, and security settings.
   Defines where static files (CSS, JS) and uploaded media files live

Python Question
14. Tuple - Immutability Enables Optimization
    Allocate less memory (no need for over-allocation like lists)
    compact, contiguous memory blocks → which boosts CPU cache performance
Memory layout optimization
Better cache locality
Precomputed metadata (like size and type)

15. List - Allocate extra space ("overhead")
    Store pointers to objects rather than the objects directly

16. Generators - 
           memory-efficient, lazy iteration, especially over large datasets or streams
    A generator is a special type of iterator that generates values on the fly instead of storing them all in memory at once.
    Instead of using return, it uses the yield keyword to produce a value, pause execution, and resume later
✅ Memory Efficient	Doesn’t load all data in memory – great for big data, files, or streams
✅ Lazy Evaluation	Values are computed only when needed
✅ Clean Syntax	Easier to read and write than manually implementing iterators
✅ Pause & Resume	Execution state is saved between yields

def count_num(maxs):
    count = 1 
    while count <= maxs:
        yield count
        count +=  1 
gen = count_num(3)
print(next(gen))
print(next(gen))
print(next(gen))
print(next(gen))

17.nums = [1, 2, 3]        # This is an iterable
it = iter(nums)         # This is now an iterator
print(next(it))

18.DeepCopy and ShallowCopy 
Think of shallow copy as cloning the outer shell but sharing the same inner data, while deep copy clones everything inside too.

19.Thread Execution
   Embedding Size 
   How to Deploy the OpenSource model in Azure AI 
   How to Build the Cloud Native Application
   How to Use the Azure Logic App and Azure Function App
   How to Use the Azure Web App
   Little Bit Knowledge about the VNet, Firewall, Network 
   Reduce function 


20 Decorator - behavior to objects or functions dynamically without modifying their structure

21 Abstract Method - from abc import ABC, abstractmethod

22 Access modifiers such as public, private, and protected.
   Public (+): Attributes and methods are accessible from outside the class
   Private (-): Attributes and methods are only accessible within the class. They are denoted by a double underscore __.
   Protected (#): Attributes and methods are accessible within the class and its subclasses. They are denoted by a single underscore _.

23 import requests

# Your Azure endpoint URL
azure_endpoint_url = "https://your-azure-endpoint.azurewebsites.net/predict"

# Sample data to be sent for prediction
data = {"feature1": 10, "feature2": 5, "feature3": 7}

# Send a POST request to the Azure endpoint with the data
response = requests.post(azure_endpoint_url, json=data)

# Check if the request was successful (HTTP status code 200)
if response.status_code == 200:
    # Parse the predictions from the response
    predictions = response.json()
    print("Predictions:", predictions)
else:
    print("Error:", response.status_code, response.text)


24 Creation of Docker Image 
# Base image
FROM python:3.9
# Set the working directory
WORKDIR /app
# Copy application files
COPY . /app
# Install dependencies
RUN pip install -r requirements.txt
# Expose a port (for web apps)
EXPOSE 5000
# Define the default command to run
CMD ["python", "app.py"]

docker build -t my-python-app .
docker run -p 5000:5000 my-python-app
docker tag my-python-app mydockerhubusername/my-python-app
docker push mydockerhubusername/my-python-app
docker exec -it my-container /bin/bash

25. Azure Functions = Azure Functions or Logic Apps	Automates document processing and retrieval workflows.

26. Azure Logic Apps - Azure Logic Apps is a serverless workflow integration platform. 

27. Azure API Management - 


CRUL 
-----
curl -X POST https://api.example.com/login -d "username=admin&password=1234"
curl -X POST https://api.example.com/login \
-H "Content-Type: application/json" \
-d '{"username": "admin", "password": "1234"}'
curl -H "Authorization: Bearer YOUR_TOKEN_HERE" https://api.example.com/secure-data


RAG And AI Agents Notebooks
---------------------------
https://colab.research.google.com/drive/1RdkYOTpx41WNLCA8BJoh3egQRMX8fpJZ?usp=sharing#scrollTo=FL8y37hhnGWn

UseCase for our Project Architecture 
----------------------------
1) Data Ingestion Pipeline - Azure Functions or Logic Apps	Automates document processing and retrieval workflows.
1) CRM Data - Connecting other API and getting the DATA.  - GET Method 
2)

AI Interview 
------------
https://www.interview.micro1.ai/start/micro1/?candidate=8817e0dd-2947-4078-a7b3-8c038b95415d&ping=ok

AI Website 
----------
https://bolt.new/~/sb1-mp4hj8v2 - Quick Protyping 
https://designwithai.substack.com/p/i-ran-the-same-prompt-through-three-ai-prototyping-tools - Prototyping website 
https://adaptive.ai/ - Adaptive AI 

Common Doubts
-------------
1) MessagePlaceholder in Langchain - AgentsSracthPad
2) Azure DevOps
3) Azure Cosmos DB 
4) Azure AI Foundry Services - Project Creation 


What to Learn Next
------------------
Event Driven Architecture 
Solution Architecture for GenAI - All Azure Service 

Research Papers
---------------
SQL-PaLM: Improved Large Language ModelAdaptation for Text-to-SQL


********** I'm Going to Create the Project and Sell the AI Agent ***********
Quantum Revolution 
------------------


Today's Learning
----------------
Azure VNET - Not all Azure services run inside an Azure Virtual Network (VNet) by default
           - Some services are publicly accessible over the internet, while others can be integrated into a VNet for security and private access.

These services can be deployed inside a VNet and accessed securely:
Virtual Machines (VMs)
Azure Kubernetes Service (AKS)
✅ Azure Virtual Machines Scale Sets
✅ Azure App Service (with VNet integration)
✅ Azure SQL Managed Instance
✅ Azure Synapse Analytics (Dedicated Pools)
✅ Azure Firewall, Azure VPN Gateway
These services can communicate privately using private IPs inside a VNet.
They can also use Network Security Groups (NSGs) to control access.

2. Services That Are Public by Default (Can Use Private Link)
These services are publicly accessible, but can be made private using Azure Private Link or VNet integration:
✅ Azure Storage (Blob, Queue, Table, File)
✅ Azure SQL Database (PaaS)
✅ Azure AI Services (OpenAI, AI Search, etc.)
✅ Azure Functions
✅ Azure App Services (Web Apps, Logic Apps)
✅ Azure Key Vault
By default, these services are publicly exposed over the internet.
Private Link allows them to be accessed privately from a VNet.

How to Ensure Services Are Private?
Use Private Link to restrict access to Azure Storage, SQL, AI services, etc.
Deploy resources inside a VNet when possible.
Use VNet Peering to connect different VNets securely.
Enable Service Endpoints to allow VNet traffic to reach public services securely.

What Does "Service Running Inside a Virtual Network" Mean?
When a service is running inside an Azure Virtual Network (VNet), it means:
✔️ The service is isolated from the public internet and can be accessed only within the VNet or through a private connection.
✔️ The service uses private IP addresses inside the VNet.
✔️ You can control access using Network Security Groups (NSGs), firewalls, and routing rules.

1. Virtual Machines (VMs)
VMs are deployed inside a VNet subnet with private IPs.
They can communicate securely with other services in the same VNet.
Public access is possible only if you configure a Public IP or VPN connection.

2. Azure Kubernetes Service (AKS) (Private Cluster)
When deployed with a private cluster, AKS nodes and services run inside the VNet.
No direct public access; only accessible via Azure VPN, ExpressRoute, or Private Link.
3. Azure SQL Managed Instance
Runs inside a VNet (unlike Azure SQL Database, which is public by default).
Can connect securely with VMs, AKS, or other resources in the same VNet.
4. Azure Synapse Analytics (Dedicated SQL Pool)
Can be deployed inside a VNet for private access.
Used in data pipelines where private networking is required.
5. Azure App Service (Web Apps) with VNet Integration
Normally public, but can be integrated with a VNet to access internal services securely.

How to Connect Services Inside a VNet?
Private IPs: Services communicate within the VNet using private IP addresses.
Private Link: Allows services like Azure Storage, Key Vault, and SQL Database to be privately accessible.
VNet Peering: Connects multiple VNets securely.
VPN Gateway / ExpressRoute: Connects on-premises networks to Azure VNets.




Azure Functions
https://myfunction.azurewebsites.net - Public Endpoint
It can access public Azure services (like Azure Storage, SQL Database) over the internet.
****
Azure Functions can be configured to access private resources in a VNet.
This is done using VNet Integration (for outbound traffic) or Private Endpoints (for fully private access).
------
Cold Start - is invoked after being idle for a period of time
Azure needs to allocate compute resources and initialize the function before execution.
Optimize Startup Time – Reduce dependencies and initialization logic in your function.
Use Durable Functions – Helps avoid cold start delays in long-running processes.
Warm Start
Happens when a function was recently executed, and its compute resources are still available.
Hot Start
The function or service is continuously running and ready to execute instantly
Standby Start
The cloud provider keeps some instances running but in a standby state to reduce cold start times.

---------
3️⃣ Auto-Scaling
✅ Azure Functions automatically scales based on demand.
✅ If traffic increases, more function instances spin up automatically.
✅ If traffic decreases, Azure scales back to zero, saving costs.
4️⃣ Event-Driven (Triggers & Bindings)
✅ Supports multiple triggers (e.g., HTTP requests, message queues, storage events).
✅ Works well with Azure services like Blob Storage, Cosmos DB, and Event Grid.
✅ Example: Run a function when a new file is uploaded to Azure Blob Storage.
6️⃣ Easy Integration with Azure Services
✅ Seamless integration with Azure Storage, AI services, databases, and IoT.
✅ Works with Azure Logic Apps, APIs, and microservices.

Examples Azure Function Usage
🔹 Automate Background Jobs – E.g., processing logs, resizing images.
🔹 Trigger-Based Processing – E.g., process messages from a queue, update a database.
🔹 API Backend – E.g., lightweight APIs without managing a full server.
🔹 Data Processing & ETL – E.g., transform data before storing it in a database.
🔹 IoT Data Processing – E.g., analyze sensor data in real time.

-------
Function.json file 
In Azure Functions, the function.json file is a configuration file that defines the bindings and triggers for a specific function. It helps Azure understand:
How the function is triggered
What inputs the function requires
What outputs the function produces

Azure Functions follow an event-driven architecture, where functions are executed in response to specific triggers or events. The function.json file acts as a declaration file that tells Azure how the function interacts with other services.

Property	Description
bindings	Defines input and output bindings.
disabled	Enables or disables the function.
scriptFile	Specifies the main function code file (for JavaScript, Python, etc.).
entryPoint	Specifies the method name to execute (for C# and Java).

{
  "bindings": [
    {
      "type": "httpTrigger",
      "direction": "in",
      "name": "req",
      "methods": ["get", "post"],
      "authLevel": "function"
    },
    {
      "type": "blob",
      "direction": "out",
      "name": "outputBlob",
      "path": "mycontainer/{rand-guid}",
      "connection": "AzureWebJobsStorage"
    }
  ],
  "disabled": false
}

/MyFunctionFolder/
  ├── function.json
  └── __init__.py (for Python)
  └── index.js (for Node.js)

The function.json file acts as the blueprint of your Azure Function, linking it with external services and defining how data flows in and out.

1.for Data Processing, 
    System Integrations
    Building Simple API's and microservices 

2.Functional Difference Between Azure Functions
                              Azure Logic Apps
                              WebJobs




Azure Logic Apps
Azure Logic Apps is a serverless workflow integration platform. 
Azure Web Apps 
Azure DevOps - How to Use the container Instance - Kubernetes Service  
Azure AI Apps - How to Depoly the AI Model 
Azure CI/CD Pipelines 

Quantum 
https://iqti.iisc.ac.in/academics/









