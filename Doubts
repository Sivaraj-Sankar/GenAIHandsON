Agentic RAG 
1) Router includes capability to request clarification for ambiguous queries
2) How pass the prompt with query with Agent - In Every call or Single Call
3) How to Manage the Memory of the Agent 
4) How to Retrieve the Response for Agentic RAG - Either by Reterival Strategy or through the Agentic CoT Approach with memory management 
5) Chunking with Metadata - How much have to give in chunk 
6) How to Manage the Session for Agent 
7) Preprocessing the Data Properly with Metadata 
8) Vector Database that support the Metadata 
9) Query should rewrite based on the prompt 
10) Summarize Agentic RAG - QA Agentic RAG 
11) Referencing the Source 
12) MCP Protocol
13) Connectors for Multiple Data Sources
14) Testing the Agentic RAG 
15) Experimenting the Agentic RAG 
16) Tool Description - for Agentic RAG 
17) Error Handling and Fallback Strategies 
18) Pydantic Object to check we receiving the Structured output from LLM 
19) How to Use the Structured Output 
20) Data Pipeline 
21) Handle edge cases explicitly
22) Actions if needed for Agents to make decisions
23) Guardrails, 
24) Responsible AI 
25) Monitoring the AI Agent 
24) Evaluating the AI Agent and Decision of AI Agent 
25) Logging 

26) Agent 1  - Rewrite Query with Selective Retrieval    Agent 2 - Reflect --- Agent 3 -- Prompt with [Respective Ouput] + [Respective Retrieval from LLM ] - Multiple Calls or Single Calls

27) How to Evaluate the Retrieved Document 


Complex PDF RAG Pipeline 
------------------------
1) Dropping relevant graphics from your context
2) Gemini 2.5 with a multimodal Embedding model like Cohere's latest Embed v4
3) Unlock vision RAG and avoid image-to-markdown conversion.
4) Combines Gemini Flash 2.5 (vision LLM) with Cohere Embed v4 (retrieval).
5) Directly retrieves & understands complex images (slides, charts, graphs, infographics).
6) Cohere Supports processing of documents up to 128,000 tokens, approximately equivalent to 200 pages, making it suitable for large-scale document analysis - adjustable embedding dimensions (e.g., 256, 512, 1024, 1536)

Cost Effective 
---------------
LlamaParse - Cost=300×0.0015=0.45 USD
Cohere     - Cost=1.5×0.47=0.705 USD


General Architecture
Build modular components
Implement robust error handling
Consider scaling requirements
Plan for monitoring and evaluation


28) how Multi Agent are working so far I created in LangGraph and CrewAI - is it waiting for other agents to complete the work , are passing the task sequentially 
    In Letta - the Multi Agent Concept is different 

29) How to Pass the Tools name to the OpenAI Function Call 
       Function Definition - Pydantic Object to create the Function Definition
    How to create the Actual Python function tool --> whith doc string to --> for LLM to understand 

30) How Manager Agent calls the other agents, by reasoning - Check the course learned crewAI, AutoGen, etc
          giving other agents as tool or how ?

31) How Async works with    - concurrently run all three agents - parallely 
async def main():
    msg = input( )
    orchestrator_output = await Runner.run(manager_agent,msg)


32) Prompt Should be build up from the layers and layers of input data 
33) Evaluation - getmaxim.ai has built a very comprehensive agent simulation and evals platform. 
34) Evaluation - Wayfound.ai 
35) Evaluation - Noveum.ai 
36) Evaluation - Instructor - https://github.com/instructor-ai/instructor - MIT License 
                 (If you’re importing an LLM API SDK, use Instructor; if you’re importing Huggingface for a self-hosted model, use Outlines.)

37) Applied LLM - https://applied-llms.org/

38) Evaluation - https://noveum.ai/en

38) MegaPrompt - Approach 
39) The specificity of task-oriented prompts means they aren't suitable for general, open-ended conversations.
    https://www.godaddy.com/resources/news/llm-from-the-trenches-10-lessons-learned-operationalizing-models-at-godaddy#h-1-sometimes-one-prompt-isn-t-enough

40) Important Techniques - https://www.godaddy.com/resources/news/llm-from-the-trenches-10-lessons-learned-operationalizing-models-at-godaddy#h-1-sometimes-one-prompt-isn-t-enough

--------------------------------------------------------------------
API Integration
----------------
Event Web API 
HTTP Web API's 

API Scaling
-----------
How to Scale API Performance in a High-Load System and Avoided CPU Overload
API - Plays a Role of Gateway that manages incoming requests from all entities 
Each API has a limited number of requests it can process 
When API is overloaded, your Whole System essentially stops, as it can't output any results without 
processing requests first 

USER (Millions of users)
         ↓
      Internet
         ↓
    [Load Balancer]
         ↓
 ┌─────────────┬─────────────┬─────────────┐
 │             │             │             │
[Backend Server 1] [Backend Server 2] [Backend Server 3] ... (Auto-scaled instances)
 (Async API App)    (Async API App)    (Async API App)
         ↓             ↓               ↓
 ┌─────────────┬─────────────┬─────────────┐
 │             │             │             │
[Cache Layer] [Database (Read Replica)] [External Services]
 (Redis Memcachedetc.)  (Async ORM, Pooling)      (if needed)

Redis / Memcached for caching frequent results
CDN (like Cloudflare) for caching static API responses

1.Scaling a highly loaded API that processes resource-intensive requests, 
2.Also show how to calculate the future load on the system and choose the most suitable instances 
  for scaling, as well as our scaling Scheme and debugging activities.
2. Look for a balance system performace and required computing resources.
Vertical Scaling[up or down] - more VM's  vs Horizontal Scaling [in or out] - several endpoints
--------------------------------------
Horizontal Scaling - enhance your system with additional physical computing power. create Sharded database 
                     deploy more nodes. 


What type of scaling should you choose for your system?
How can you calculate the future load on your system?
How can you choose instances for scaling?
How can you design and debug a cloud scaling system?

Eg:Each request takes between 30 seconds and one minute and up to 20% of server CPU power.
An excessive number of requests should not cause the machine to freeze and make it inoperable.

Be able to process up to five million requests per day
Withstand a heavy bandwidth load in order to communicate with third-party services

REST API
SQS
Lambda
DynamoDB

Application Load Balancer
EC2
DynamoDB

Application Load Balancer
EC2
DynamoDB

4 CPUs, 8 GB RAM - instance can process 60 to 120 requests per minute, or 2 to 3 requests per second, before crashing.


Wrote a simple application prototype with unchangeable logic.
Launched the easiest and cheapest instance on AWS and loaded it until it failed.
Saw how many queries this instance completed and which criteria made it fail.
Launched a more powerful instance and tried to crash it with our prototype.

We used JMeter to find the maximum load on AWS instances until we found the most suitable ratio of instance parameters and time to crash

1.Failure of one API request can affect other requests.
2.When one request overloaded a browser, it couldn’t process subsequent requests. To fix this, we isolated each process and limited the load by creating internal requests and a request queue for each server.
3.The first step was to create a worker that would run our program independently so that in case of errors, we would lose only one request instead of all operations. 
4.This worker takes one task at a time from the queue after completing the previous one. In our case, the CPU load per worker was 7%.
5.Next, we increased the number of workers until the CPU was 80% loaded. This way, we got an isolated process with a predictable load and created a number of parallel tasks for the instance to process.
6.Our API keeps the connection active until it gets a response. Under a heavy load, it took our system three to five minutes to respond, and during this time the application load balancer ended the connection. We increased the maximum connection time for the API to three to four minutes. During this time, we can create a new instance if needed.  
7.However, this method of scaling has several disadvantages you need to be aware of. The request queue inside the instance helps to manage API performance, but it shouldn’t accumulate more requests than the instance can process within three minutes. Since the API connection lasts for three to four minutes, the API won’t get responses to requests that take longer. That’s why we need to launch a new instance during this time.

Developing Robust API's 
-----------------------
1. Designing High-Quality APIs,
KISS - Keep It Simple, Stupid.
2.Use Standard, concrete and shared terms that are familiar to most people 
3.Allow application developers to do things in only one way, rather than offering multiple confusing options.
4.Design the API with the needs of the client in mind
5.Medium Grained Resources - You Should use medium grained, not fine nor coarse. 
  Resources shouldn't be nested more than two level deep 
6. Snake_Case or CamelCase for attributes and parameters. 
7. for using more than one word in URL - spinal-case 
8. Versioning mandatory in the URL at the highest scope (major versions). 
9. You may support at most two versions at the same time (Native apps need a longer cycle)

Collection Resource: /employees
Instance Resources: /employees/11


Django Views
------------
Function-Based Views (FBV)
    ↓
Class-Based Views (CBV)
    ↓
Generic Class-Based Views (GCBV) → Special ready-made
    ↓
ViewSets → For APIs (Django REST Framework)


Interview Question
------------------
1.What is Whitelist - Whitelisting in APIs is a security practice used to control access to an API by explicitly allowing only certain clients, 
                      IP addresses, domains, or applications to use it
This is common for internal APIs or services accessed only from a specific office or server.
IP addresses
API keys or tokens
Domains or referrers
User agents
Applications or client IDs
-Limitations of Whitelisting
IP spoofing (though rare if HTTPS is used) can be a risk if relying only on IP addresses.
Not suitable for mobile apps or dynamic IPs.
Managing large or changing whitelists can become complex

2. How Whitelist Implemented - 
Firewall or API Gateway level (e.g., AWS API Gateway, Apigee, NGINX)
Within application logic (e.g., checking IP or key manually)
Cloud IAM policies (e.g., Google Cloud IAM, AWS IAM roles)

3.Different Whitelisting 
IP Address Whitelisting
API Key Whitelisting - Developer should register for whitelisting 
Domain/Origin Whitelisting
OAuth Client Whitelisting

4.IP Spoofing
IP spoofing occurs when a hacker modifies the packet headers to insert a fake (spoofed) source IP address.
eg. of of the example of attacking[Session Hijacking] - Rare, but spoofing can be used to hijack a TCP session if sequence numbers are predictable.
Authentication mechanisms: Don't rely on IP alone—use tokens, keys, or certificates.


5.Rate Limiting - Only allow approved users to consume API resources, which protects performance
These can be global (per user/IP) or granular (per endpoint, per API key, per method, etc.)
429 Too Many Requests
system keeps track of requests per client, and once a client exceeds their quota, the system can
-Reject the request with an HTTP status (e.g., 429 Too Many Requests)
-Queue the request (in some APIs)
-Temporarily block the client (a "cooldown" or "timeout")
-Apply backoff logic (e.g., wait before retrying)

Rate Limiting Algorithms
 Token Bucket
Tokens are added to a “bucket” at a fixed rate
Each request consumes a token.
If no tokens are left → request is denied.

Leaky Bucket
Similar to token bucket but allows tokens to “leak” at a constant rate.
Smoothens traffic spikes over time.

Fixed Window
Counts requests in a fixed time window (e.g., per minute).
Simple but has boundary issues (spike at end/start of window).

 Sliding Window
Improves on fixed window by using rolling time periods
More accurate in evenly enforcing limits

How to implement the Rate Limit 
API Gateways (e.g., AWS API Gateway, NGINX, Kong)
Backend servers or middleware
Web Application Firewalls (WAF)
CDNs (e.g., Cloudflare)


6.Azure API Management (APIM) [You need a centralized API management layer across different backends
                               You're integrating with Azure services]
Centralized API gateway for managing REST and SOAP APIs
Rate limiting, quotas, throttling via policies
Supports OpenAPI, WSDL, Swagger, and GraphQL (preview)
Backend integration with Azure Functions, App Services, Logic Apps, etc
Built-in analytics, logging, and monitoring
Security via OAuth2, JWT validation, IP filtering, and more
Supports multi-region deployments and versioning

7.Different API 
REST, HTTP, WebSocket
REST, SOAP, GraphQL

8.Authentication - Think of it as a login check.
  -username and password
  -Using Multi-Factor Authentication (MFA)
  -Presenting a valid API key or token
  -Signing in with Google, Azure AD, or GitHub(OAuth/OpenID)


9.Authorization - Authorization is the process of checking what actions an authenticated user is allowed to perform
Think of it as permission checking
  -An API token may only allow read access to data, not write

10.Authentication
Authentication methods:
In Web/API Context
  -Basic Auth
  -OAuth2 / OpenID Connect
  -JWT (JSON Web Tokens)
  -API Keys
  -SAML

11.Oauth ==== -  - - - - - Client redirects user to Authorization Server
App opens browser: https://accounts.google.com/o/oauth2/v2/auth?...
Includes client_id, scope, and redirect_uri
User logs in & approves access
Google shows login + consent screen
User clicks “Allow”
Authorization Server redirects back to Client
Sends an Authorization Code to the app via redirect_uri
Client exchanges Code for Access Token
App sends code + secret to Authorization Server
Server returns an Access Token (and optionally a Refresh Token)
Client uses Access Token to access Resource
App calls the API with the token:
Authorization: Bearer ACCESS_TOKEN

12. Middleware Task in Django
Modify request before view	Add user data, parse headers, attach tokens
Process response after view	Add CORS headers, compress response
Handle exceptions globally	Catch and log errors or show error pages
Control access	Block IPs, enforce authentication
Performance measurement	Log timing or request metrics

13. Central Configuration Hub - central configuration hub - Settings.py
   How should your app behave 
   database setup, installed apps, middleware, templates, and security settings.
   Defines where static files (CSS, JS) and uploaded media files live

Python Question
14. Tuple - Immutability Enables Optimization
    Allocate less memory (no need for over-allocation like lists)
    compact, contiguous memory blocks → which boosts CPU cache performance
Memory layout optimization
Better cache locality
Precomputed metadata (like size and type)

15. List - Allocate extra space ("overhead")
    Store pointers to objects rather than the objects directly

16. Generators - 
           memory-efficient, lazy iteration, especially over large datasets or streams
    A generator is a special type of iterator that generates values on the fly instead of storing them all in memory at once.
    Instead of using return, it uses the yield keyword to produce a value, pause execution, and resume later
✅ Memory Efficient	Doesn’t load all data in memory – great for big data, files, or streams
✅ Lazy Evaluation	Values are computed only when needed
✅ Clean Syntax	Easier to read and write than manually implementing iterators
✅ Pause & Resume	Execution state is saved between yields

def count_num(maxs):
    count = 1 
    while count <= maxs:
        yield count
        count +=  1 
gen = count_num(3)
print(next(gen))
print(next(gen))
print(next(gen))
print(next(gen))

17.nums = [1, 2, 3]        # This is an iterable
it = iter(nums)         # This is now an iterator
print(next(it))

18.DeepCopy and ShallowCopy 
Think of shallow copy as cloning the outer shell but sharing the same inner data, while deep copy clones everything inside too.

19.Thread Execution
   Embedding Size 
   How to Deploy the OpenSource model in Azure AI 
   How to Build the Cloud Native Application
   How to Use the Azure Logic App and Azure Function App
   How to Use the Azure Web App
   Little Bit Knowledge about the VNet, Firewall, Network 
   Reduce function 
   
   




CRUL 
-----
curl -X POST https://api.example.com/login -d "username=admin&password=1234"
curl -X POST https://api.example.com/login \
-H "Content-Type: application/json" \
-d '{"username": "admin", "password": "1234"}'
curl -H "Authorization: Bearer YOUR_TOKEN_HERE" https://api.example.com/secure-data


RAG And AI Agents Notebooks
---------------------------
https://colab.research.google.com/drive/1RdkYOTpx41WNLCA8BJoh3egQRMX8fpJZ?usp=sharing#scrollTo=FL8y37hhnGWn

API UseCase for our project
----------------------------
1) CRM Data - Connecting other API and getting the DATA.  - GET Method 
2)

AI Interview 
------------
https://www.interview.micro1.ai/start/micro1/?candidate=8817e0dd-2947-4078-a7b3-8c038b95415d&ping=ok

AI Website 
----------
https://bolt.new/~/sb1-mp4hj8v2 - Quick Protyping 
https://designwithai.substack.com/p/i-ran-the-same-prompt-through-three-ai-prototyping-tools - Prototyping website 
https://adaptive.ai/ - Adaptive AI 

Common Doubts
-------------
1) MessagePlaceholder in Langchain - AgentsSracthPad
2) Azure DevOps
3) Azure Cosmos DB 
4) Azure AI Foundry Services - Project Creation 


What to Learn Next
------------------
Event Driven Architecture 
Solution Architecture for GenAI - All Azure Service 

Research Papers
---------------
SQL-PaLM: Improved Large Language ModelAdaptation for Text-to-SQL


********** I'm Going to Create the Project and Sell the AI Agent ***********
Quantum Revolution 
------------------


Quantum 
https://iqti.iisc.ac.in/academics/









