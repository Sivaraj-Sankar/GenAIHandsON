Agentic RAG 
 

1) Router includes capability to request clarification for ambiguous queries
2) How pass the prompt with query with Agent - In Every call or Single Call
3) How to Manage the Memory of the Agent 
4) How to Retrieve the Response for Agentic RAG - Either by Reterival Strategy or through the Agentic CoT Approach with memory management 
5) Chunking with Metadata - How much have to give in chunk 
6) How to Manage the Session for Agent 
7) Preprocessing the Data Properly with Metadata 
8) Vector Database that support the Metadata 
9) Query should rewrite based on the prompt 
10) Summarize Agentic RAG - QA Agentic RAG 
11) Referencing the Source 
12) MCP Protocol
13) Connectors for Multiple Data Sources
14) Testing the Agentic RAG 
15) Experimenting the Agentic RAG 
16) Tool Description - for Agentic RAG 
17) Error Handling and Fallback Strategies 
18) Pydantic Object to check we receiving the Structured output from LLM 
19) How to Use the Structured Output 
20) Data Pipeline 
21) Handle edge cases explicitly
22) Actions if needed for Agents to make decisions
23) Guardrails, 
24) Responsible AI 
25) Monitoring the AI Agent 
24) Evaluating the AI Agent and Decision of AI Agent 
25) Logging 

26) Agent 1  - Rewrite Query with Selective Retrieval    Agent 2 - Reflect --- Agent 3 -- Prompt with [Respective Ouput] + [Respective Retrieval from LLM ] - Multiple Calls or Single Calls

27) How to Evaluate the Retrieved Document 


General Architecture
Build modular components
Implement robust error handling
Consider scaling requirements
Plan for monitoring and evaluation


28) how Multi Agent are working so far I created in LangGraph and CrewAI - is it waiting for other agents to complete the work , are passing the task sequentially 
    In Letta - the Multi Agent Concept is different 

29) How to Pass the Tools name to the OpenAI Function Call 
       Function Definition - Pydantic Object to create the Function Definition
    How to create the Actual Python function tool --> whith doc string to --> for LLM to understand 

30) How Manager Agent calls the other agents, by reasoning - Check the course learned crewAI, AutoGen, etc

31) How Async works with    - concurrently run all three agents - parallely 
async def main():
    msg = input( )
    orchestrator_output = await Runner.run(manager_agent,msg)


32) Prompt Should be build up from the layers and layers of input data 
33) Evaluation - getmaxim.ai has built a very comprehensive agent simulation and evals platform. 
34) Evaluation - Wayfound.ai 
35) Evaluation - Noveum.ai 
36) Evaluation - Instructor - https://github.com/instructor-ai/instructor - MIT License 
                 (If you’re importing an LLM API SDK, use Instructor; if you’re importing Huggingface for a self-hosted model, use Outlines.)

37) Applied LLM - https://applied-llms.org/

38) Evaluation - https://noveum.ai/en

38) MegaPrompt - Approach 
39) The specificity of task-oriented prompts means they aren't suitable for general, open-ended conversations.
    https://www.godaddy.com/resources/news/llm-from-the-trenches-10-lessons-learned-operationalizing-models-at-godaddy#h-1-sometimes-one-prompt-isn-t-enough

40) Important Techniques - https://www.godaddy.com/resources/news/llm-from-the-trenches-10-lessons-learned-operationalizing-models-at-godaddy#h-1-sometimes-one-prompt-isn-t-enough



Quantum 
https://iqti.iisc.ac.in/academics/

********** I'm Going to Create the Project and Sell the AI Agent ***********
Quantum Revolution 
------------------


AI Interview 
https://www.interview.micro1.ai/start/micro1/?candidate=8817e0dd-2947-4078-a7b3-8c038b95415d&ping=ok

AI Website 
https://bolt.new/~/sb1-mp4hj8v2 - Quick Protyping 
https://designwithai.substack.com/p/i-ran-the-same-prompt-through-three-ai-prototyping-tools - Prototyping website 
https://adaptive.ai/ - Adaptive AI 


Research Papers
SQL-PaLM: Improved Large Language ModelAdaptation for Text-to-SQL






