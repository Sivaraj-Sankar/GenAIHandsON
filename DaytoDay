July 2025

Index
Top Reasearcher 
Evals and Benchmarks - LLM
RAG Evaluation 
Evaluating LLM-Based Agents
State Management in Backend
Authentication Methods
Session-Based Authentication 
Query Param 
MongoDB - Key  
FrontEnd Interview Preparation 
UML
Figma
LLM Orchestration 
Contextlib 
Resources 
Alembic 
Enterprise Agent Settings

Preparation 
1.Async 
2.Generator 
3.Caching 
4.Deploying LLM 
5.System Design 
6.Azure AI Foundry 
7.Azure Agent Service 








Top Reasearcher 
---------------
Trapit Bansal - RL CoT - o-series model at openAI
Shuchao Bi - co-creater of GPT-4o voice mode and o4-mini 
             Multi-modal Post-Training at OpenAI 
Huiwen Chang - co-creator of GPT-4o's image generation, 
             - MaskGIT and Muse text-to-image architectures at Google Research 
Ji Lin - o3/o4-mini, GPT-4o, GPT-4.1, GPT-4.5, 4o-imagegen and Operator Reasoning stack 
Joel Pobar - Inference at Anthropic. 
Jack Rae - pre-training tech lead for Gemini and reasoning for Gemini 2.5. Led Gopher and chinchilla early 
           LLM efforts at Deepmind
Hongyu Ren - Co-Creator of GPT-4o, 4o-mini, o1-mini o3-mini, o3 and o4-mini. Previously leading a group for post-training of OpenAI 
Johan Schalkwyk - former Google Fellow, 
Pei Sun - post-Training, coding, and reasoning of Gemini at Google Deepmind
          Waymo's Perception models 
Jiahui Yu - co-creator of o3, o4-mini, GPT-4.1 and GPT-4o. Previously led the perception team at OpenAI, and co-led multimodal at Gemini
Shengjia Zhao - ChatGPT, GPT-4, all mini models, 4.1 and o3. Previously synthetic data at openAI
Alexandr Wang: Chief AI Officer Meta - Scale AI Company

Evals and Benchmarks - LLM
--------------------
Benchmarks - Standardized tests / Evaluation suites used to measure and compare the performance of different models
             across a variety of tasks.
 - These Benchmarks help researchers, developers, and users understand how well an LLM performs in specific areas 
 - Reasoning - Comprehension - Coding - Translation - Safety 

Common Benchmarks
MMLU
HELLASWAG
ARC
GSM8K 
BIG-Bench (BBH) 


Evaluation Metrics - NLP Evaluation
-----------------------------------
The model's prediction is compared to the labeled ground truth 
Metrics like Accuracy, BLEU, F1, pass@k, ROUGE etc are used depending on the task 

Classification        - Accuracy, F1      
QA (Short answer)     - Exact Match (EM), F1
Translation           - BLEU, METEOR 
Code Generation       - pass@k, correctness 
Summarization         - ROUGE, BLEU 
Math (GSM8K)          - Exact answer matching 

RAG Evaluation 
--------------
Evaluate Retrieval Quality - Are you retrieving the right context documents
Recall@k    - % of times the correct doc is in top-k 
Precision@k - % of top-k docs that are relevant 
MMR - Mean Reciprocal Rank 
nDCG - Ranking Quality of relevant documents

def recall_at_k(retrieved_docs,relevant_docs,k=5):
  hits = sum([1 for doc in retrieved_docs[:k] if doc in relevant_docs])
  return hits / min(k,len(relevant_docs))

Evaluate Generation Quality - Is the final answer accurate, complete or grounded 
Exact Match - Text match with groun-truth answer 
ROUGE/BLEU  - Token overlap (for summaries/QA) 
Faithfulness/Groundedness - Is the answer supported by retrieved docs
F1 Score - Partial Match (word overlap, e.g. for QA) 
Human Eval - Best for complex answers (correct, useful) 

def exact_match(pred, label):
  return pred.strip().lower() == label.strip().lower()

Evaluate Faithfulness / Hallunciation - Specific to RAG
Is the Answer based only on retrieved documents, or is it hallucinating 
Attribution/Grounding Tests : Does Every fact appear in the source 
RAGAS (Hugging Face): End-to-End RAG Evaluation Tool 

from ragas.evaluation import evaluate 
from ragas.metrics import faithfulness, answer_relevancy
results = evaluate(questions=questions,contexts=contexts,answers=answers,metrics=[faithfulness,answer_relevancy],)
print(results)

Pipeline for RAG - Evaluation 
  {"query":
  "retrieved_docs":
  "generated_answer":
  gold_answer":
}
you can evaluate 
Retrieval: Does Retrieved_docs include the sentence about Paris ?
Generation: Does generated_answer match gold_answer
Grounding: Is "Paris" found in retrieved_docs ?


Retrieval - FAISS BM25 ColBERT
Generation -  GPT, T5, LLaMA, etc 
Evaluation - RAGS, Llamaindex Evals, Trulens, Langchain evals 

Building a Test set for RAG evaluation 
Implementing custom metrics 
Comparing two RAG versions (e.g. BM25 vs embedding retriever) 

Evaluating LLM-Based Agents 
---------------------------

Evaluating AI Agents 
Agent Capabilities Evaluation - Planing and Multi-Step Reasoning  - AQUA-RAT
                                Function Calling - Tool Use 
                                Self-Reflection 
                                Memory 
                          
Application-Specific Agent Evaluation - 
Generalist Agents Evaluation 
Frameworks for Agent Evaluation 


Agentic AI's Web Search and Reasoning capabilities involves a multi-dimensional approach. 
- Compile a dataset of queries that cover
  Typical Searches 
  Edge Cases - vague, ambiguous or trick questions
  Multi-Step Tasks - requiring search + synthesis 

Quantitative Metrics 
Apply both Information Retrieval (IR) and agenti-specific metrics
IR Metrics 
* Precision@k, Recall, nDCG - measure relevance and ranking quality 
* Session success rate/ CTR - track how often user clicks or engages meaninfully 

Agentic AI Metrics (from Galileo's taxonomy) 
System Metrics: Latency, token usage, cost per task 
Task Success: Percentage of tasks completed correctly
Quality - instruction adherence, output format, factual accuracy
Tool Interaction - correct tool selection and parameter usage 

Tool-call accuracy - Did it choose and use the search tool appropriately 
Plan-Exectuion - Where intermediate steps logical and necessary ? Logging Traces/ 

Benchmark with known Evaluations
Designed for web-browsing agents
WebGames, BEARCUBS - simulate realistic browsing and retrieval scenarios 
InfoDeepSeek - evaluates retrieval + generation quality 


Drift in Tool Usage 
Retrieval quality 

Compare different versions v1 and v2 using statistical significance tests to validate improvements

State Management in Backend  - Like Flask & Django & FastAPI
---------------------------
State Management in the backend refers to how a web application tracks and manages data across different user interactions, sessions, or requests. 
Since HTTP is stateless by default (each request is independent and doesn't retain memory of previous interactions), backend frameworks like FastAPI, Flask, and Django need to explicitly implement ways to maintain state across requests

State Type	Description
Session State	Keeps user-specific data (e.g. login info) across requests.
Application State	Data shared across all users during the lifetime of the app (e.g. cache).
Request State	Temporary data for a single HTTP request.
Database State	Persistent data stored in a DB and retrieved as needed.

State Management in FastAPI, Flask, Django
1. Request State
Handled automatically. Each request has its own context.
Flask: via request object from flask package
FastAPI: via dependency injection (request passed into endpoint)
Django: via request object in view functions

from fastapi import Request

@app.get("/")
def read_root(request: Request):
    client_host = request.client.host
    return {"client": client_host}


2. Session State (User-specific data)
Flask: Has a built-in session object backed by cookies (signed with secret key).
FastAPI: No built-in session support, but can be added using middleware or third-party packages like starlette.middleware.sessions.
Django: Built-in session middleware with support for DB, cache, or file-based sessions.


from flask import session

@app.route('/login')
def login():
    session['user'] = 'sivaraj'
    return 'Logged in'

from starlette.middleware.sessions import SessionMiddleware

app.add_middleware(SessionMiddleware, secret_key='your-secret')

@app.get("/set-session")
def set_session(request: Request):
    request.session["user"] = "sivaraj"
    return {"message": "session set"}


3. Application State
Shared across all requests and users.
Flask: Use app.config or global variables (not recommended for complex apps).
FastAPI: Use app.state for app-level storage.
Django: Usually uses caching or settings module for shared state.


@app.on_event("startup")
def startup_event():
    app.state.model = load_your_model()

@app.get("/predict")
def predict():
    model = app.state.model
    return model.predict(...)

4. Persistent State (Database)
State stored in a database is the most reliable way to manage long-term state across users and sessions.
Django uses ORM (models.py) and handles state via database.
Flask and FastAPI typically use SQLAlchemy, Tortoise ORM, Beanie (MongoDB), etc

Additional Considerations
Authentication/Authorization: Uses session, JWT, or OAuth to manage state.
Caching: Redis or Memcached can store temporary shared or user-specific state.
WebSocket State: Use connection state in memory or Redis for real-time apps.

Framework	Session Support	Application State	ORM/DB Integration
Flask	Built-in (session)	g, app.config	SQLAlchemy, etc.
FastAPI	Via Middleware	app.state	SQLAlchemy, Tortoise, Beanie
Django	Built-in Middleware	Django settings/cache	Django ORM


Authentication/Authorization in Backend (State Management Perspective) 
Since HTTP is stateless, we need to use mechanisms like sessions, JWT, or OAuth tokens to maintain user-specific data (i.e., state) across multiple requests after the user logs in

Authentication	Verifying who the user is (e.g., username/password).
Authorization	Verifying what the user is allowed to do (e.g., access certain APIs).

Once a user logs in (authenticates), we need a way to remember who they are on every subsequent request.
That‚Äôs where state comes in ‚Äî by using Session, JWT, or OAuth mechanisms

1. Session-based Authentication (Server-Side State)
Stores user login info in memory or database on the server.
Sends a session ID to the client as a cookie.
On each request, the client sends the session ID; the server looks up the user.

Django Example 
# Login view in Django
def login_view(request):
    if request.method == "POST":
        user = authenticate(username="sivaraj", password="pass")
        if user:
            login(request, user)  # Django stores session

Server-side state:
Stored in DB or cache (Redis).
Requires server memory or infrastructure to maintain sessions.
More secure but harder to scale horizontally.

2. JWT (JSON Web Token) - (Stateless Authentication)
Once user logs in, the server issues a signed token.
This token contains user info, expiry, and is self-contained.
On every request, the client sends the token (usually in the Authorization header).

from fastapi import Depends, HTTPException
from fastapi.security import OAuth2PasswordBearer
import jwt

oauth2_scheme = OAuth2PasswordBearer(tokenUrl="token")

def get_current_user(token: str = Depends(oauth2_scheme)):
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=["HS256"])
        user = payload.get("sub")  # user identifier
        return user
    except jwt.ExpiredSignatureError:
        raise HTTPException(status_code=401, detail="Token expired")

Client-side state:
Stored in the browser or app (e.g., localStorage or memory).
Scales easily (stateless).
Needs good security practice (e.g., token rotation, short expiry).

Client-side state:
Stored in the browser or app (e.g., localStorage or memory).
Scales easily (stateless).
Needs good security practice (e.g., token rotation, short expiry).

3. OAuth2 / OpenID Connect (Third-party Authentication)
Used to delegate authentication to another provider like Google, GitHub, Facebook.
Users login via a third-party.
You get a token (like JWT or an access token).
You use that token to access APIs.

Used in: Social login, enterprise apps, microservices
Example flow:
User clicks "Login with Google"
Redirected to Google, they log in
Redirected back to your app with authorization code
Your app exchanges code for access token
You can now access user data or validate session

Method	Where is State Stored?	Stateless?	Notes
Session	On the server (DB, memory, Redis)	‚ùå No	Easy to manage but hard to scale horizontally
JWT	In the token (client-side)	‚úÖ Yes	Fast and scalable; no need to store anything on server
OAuth2	On client + third-party auth server	‚úÖ Mostly	You trust another system to manage auth and token


I can provide:

Session-based login for Django/Flask
JWT login with FastAPI
OAuth login using Google
Let me know your use case (e.g., REST API with JWT for React frontend), and I‚Äôll give you full code for that.


Login Method
-------------
POST /login
Content-Type: application/json

{
  "username": "sivaraj",
  "password": "your_password"
}


200 OK
Content-Type: application/json

{
  "access_token": "eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiJzaXZhcmFqIiwibmJmIjoxNzI5MDY5NDIwLCJleHAiOjE3MjkwNzMwMjB9.uCdpDShc4PQfGm5GL7FYuPC7KnFgPMql0yz1LBKTt20",
  "token_type": "bearer"
}

The token is signed with a secret key and may include:
sub: subject (user ID or username)
exp: expiration time
nbf: not before time
any custom claims (roles, scopes, etc.)


3. Client Stores the JWT
Client stores the token in memory or browser storage:
Browser: localStorage, sessionStorage
React/Frontend App: Redux store or local variable


GET /user/profile
Authorization: Bearer <JWT_TOKEN_HERE>

Decodes the token using the secret key.
Verifies exp, nbf, and sub.
If valid, returns data; else returns 401 Unauthorized


200 OK
Content-Type: application/json

{
  "username": "sivaraj",
  "email": "sivaraj@example.com",
  "role": "admin"
}



Authentication Methods 
----------------------
Auth Method	Where State is Stored	Stateless?	Suitable For	Pros	Cons
Session-Based	Server (DB, Redis, memory)	‚ùå No	Traditional web apps (Django, Flask), server-rendered UIs	Easy to implement, built-in CSRF protection	Not scalable across multiple servers without shared session
JWT (Token)	Client (token in header)	‚úÖ Yes	SPAs (React/Vue), mobile apps, APIs, microservices	Scales easily, no server-side state	No built-in logout, token revocation is hard
OAuth2 / OIDC	Client + 3rd-party provider	‚úÖ Mostly	Login via Google, GitHub, Facebook, enterprise SSO	Delegated auth, secure, standard for large systems	Complex to implement, requires trust in provider
API Key	Client (key in header)	‚úÖ Yes	Internal services, server-to-server communication	Simple, fast	No user context, poor granularity, hard to rotate securely
Basic Auth	Client (username:password)	‚úÖ Yes	Quick prototyping, scripts	Extremely simple	Insecure (no hashing), credentials sent on every request


Basic Authentication
How it works: Username and password encoded in Base64 and sent in each request.
Use when:
Quick development or testing scripts.
Internal systems without sensitive data.
Not recommended for production without HTTPS.

 API Key Authentication
How it works: A unique key is provided per client; key is passed in the header of every API call.
Use when:
It's a backend-to-backend system.
You don't need user-specific data, just service-level access.
Example: A backend service pulling weather data using an API key.


3. OAuth2 / OpenID Connect
How it works: Uses authorization servers (like Google) to authenticate and provide access tokens.
Use when:
You want SSO (Single Sign-On).
You want to allow users to log in using existing identities (Google, Microsoft).
You‚Äôre building enterprise or third-party integration apps.
Example: "Login with Google" on a SaaS product.

 JWT (JSON Web Token)
How it works: Server returns signed token (JWT) on login; client stores it and sends in Authorization header.
Use when:
You're building SPAs with React, Angular, or Vue.
You need stateless and scalable APIs.
You have mobile apps or microservices architecture.
Example: React + FastAPI frontend/backend combo with mobile clients.


Session-Based Authentication
How it works: Server stores session ID after login; client stores session ID in a cookie.
Use when:
You use server-rendered pages (like in Django or Flask templates).
You don‚Äôt need to scale horizontally without session stores.
Example: Classic web dashboard for internal admin system.


Session-Based Authentication
Session-Based Authentication Requires Server-Side State

In session-based authentication, the user session is stored on the server, often in:
Memory (RAM)
A local file
A database
A shared session store like Redis

So, when a user logs in:
Server generates a session ID
Server stores the session data (e.g., user info) on the server
Server sends back a cookie with session ID to the client
Client sends that cookie in each request
Server looks up the session using the session ID

Horizontal Scaling = Multiple Servers
Horizontal scaling means adding more servers or instances (e.g., in a load-balanced setup) to handle more traffic.
                 +-------------+
User ‚Üí Internet ‚Üí| LoadBalancer|‚Üí Server 1
                 +-------------+‚Üí Server 2
                                 Server 3

A user logs in, and Server 1 stores their session in its memory.
Next request goes to Server 2 (due to load balancing).
Server 2 doesn't have that session info, so the user appears logged out or gets an error.


If sessions are stored only in each server‚Äôs local memory, then:
"You can't scale horizontally"
...unless you use a shared session store (like Redis) accessible by all servers.

Solution: Session Store (Shared State)
All servers connect to Redis or Database to fetch session info.

No matter which server handles the request, it can find the session.

plaintext
Copy
Edit
Client ‚Üí Load Balancer ‚Üí Server 1 or Server 2
                       ‚Üò Redis (shared session store)



JWT Doesn‚Äôt Have This Problem
JWT is stateless
No session is stored on the server
The token carries all necessary user info
Any server can validate it using a shared secret key
So JWT is better suited for horizontal scaling, especially in cloud-native or microservice-based apps.


Concept	Session-Based	JWT-Based
Needs shared session store?	‚úÖ Yes	‚ùå No
Scales easily across servers?	‚ùå Only with shared store	‚úÖ Yes
Stores state on server?	‚úÖ Yes (session data)	‚ùå No (client stores JWT)


Param in API 
------------
Value	How You Get It	Where It Comes From
rm_id	From JWT token	After login (attached to auth header)
application_id	From route or page context	URL param or selected application
message	From form input	RM types in message box


GET Chat History (with Path and Query Params)
GET /api/applications/abc123/chat?limit=50&sort=desc


Use Case	Parameter Type to Use	Why
Identify a specific resource	Path Param	Cleaner, more RESTful: /applications/123
Filter/sort/paginate a list	Query Param	Optional and flexible: ?sort=desc
Send structured data	Body Param (POST/PUT)	Useful for complex inputs like forms or messages
Auth, content negotiation	Header Param	Metadata like tokens or content type


Query Param 
-----------
Query parameters are part of the URL, used to send optional data like filters, pagination, search terms, etc.
They appear after the ? in the URL.
Multiple query params are joined with &

Let‚Äôs say you want to fetch chat history for an application:
// JavaScript/React/Frontend
const applicationId = 'abc123';
const limit = 20;
const sort = 'desc';

fetch(`/api/applications/${applicationId}/chat?limit=${limit}&sort=${sort}`, {
  method: 'GET',
  headers: {
    'Authorization': `Bearer ${token}`,
    'Content-Type': 'application/json'
  }
});


GET /api/applications/abc123/chat?limit=20&sort=desc

app.get('/api/applications/:applicationId/chat', (req, res) => {
  const applicationId = req.params.applicationId; // from path
  const limit = req.query.limit; // from query string
  const sort = req.query.sort;

  console.log(applicationId); // "abc123"
  console.log(limit);         // "20"
  console.log(sort);          // "desc"

  // Use these values to fetch data from DB
});



def chat_view(request, application_id):
    limit = request.GET.get('limit')  # "20"
    sort = request.GET.get('sort')    # "desc"
    # application_id is from the path

    # You can use these to query the database


from fastapi import FastAPI, Query

@app.get("/api/applications/{application_id}/chat")
def get_chat(application_id: str, limit: int = Query(20), sort: str = Query("desc")):
    return {
        "application_id": application_id,
        "limit": limit,
        "sort": sort
    }


Param	Example	Used For
limit	?limit=50	Pagination
offset	?offset=10	Skip records (pagination)
sort	?sort=asc	Sort order
filter	?status=InProgress	Filter by status or keyword
search	?q=John	Search text


Always validate query params on the backend.
Provide default values in case params are missing.
Be strict with types (especially int, bool, etc.).


Frontend builds URL with ?key=value format.
Backend reads them via req.query (Express), request.GET (Django), or as function args (FastAPI).
Ideal for optional parameters like filters, sorts, and pagination.


MongoDB - Key  
------------
Note: MongoDB won‚Äôt validate that application_id: "app123" actually exists in applications. You have to enforce this in your application logic

Option	Description
Manual Checks	Validate references in code before inserting/updating
Data Embedding	Embed related data if it's read together and not huge
Two-Phase Commits	Use transactions (MongoDB 4.0+) for atomicity across collections
Mongoose (ODM)	Provides schema models and can define references


const ChatLogSchema = new mongoose.Schema({
  application_id: { type: mongoose.Schema.Types.ObjectId, ref: 'Application' },
  message: String
});


Excellent question ‚Äî let's look at how PostgreSQL works with FastAPI, especially regarding primary keys, foreign keys, and validation. This is one of the biggest differences between a relational (SQL) database like PostgreSQL and a NoSQL DB like MongoDB

Yes ‚Äî PostgreSQL enforces key constraints!
When you define a foreign key or primary key in PostgreSQL, it is enforced at the database level, not just in the application

How PostgreSQL Works with FastAPI
You typically use SQLAlchemy (ORM) or Tortoise ORM to connect PostgreSQL with FastAPI.

Let‚Äôs walk through it

Define Your Models with Relationships
# models.py

from sqlalchemy import Column, Integer, String, ForeignKey
from sqlalchemy.orm import relationship
from database import Base

class Application(Base):
    __tablename__ = "applications"
    id = Column(Integer, primary_key=True, index=True)
    customer_name = Column(String)

class ChatLog(Base):
    __tablename__ = "chat_logs"
    id = Column(Integer, primary_key=True, index=True)
    application_id = Column(Integer, ForeignKey("applications.id"))  # FK enforced!
    message = Column(String)

    application = relationship("Application")


Create the Tables (with Constraints)

alembic upgrade head


@app.post("/chat")
def add_message(msg: ChatMessageSchema, db: Session = Depends(get_db)):
    chat = ChatLog(**msg.dict())
    db.add(chat)
    db.commit()
    return {"status": "message added"}

psycopg2.errors.ForeignKeyViolation: insert or update on table "chat_logs" violates foreign key constraint



Feature	PostgreSQL + FastAPI
Primary key	‚úÖ Auto-enforced via schema
Foreign key	‚úÖ Enforced; DB will reject invalid IDs
Cascading deletes/updates	‚úÖ Supported with ON DELETE CASCADE
Transactions	‚úÖ Built-in with db.commit()
Schema migrations	‚úÖ Use Alembic


Concept	MongoDB	PostgreSQL + FastAPI
Primary Key	Yes (_id)	Yes (id, auto-incremented or UUID)
Foreign Key	‚ùå Not enforced	‚úÖ Enforced (FK constraints)
Validation	Manual in app	Automatic at DB level
Best ORM	Mongoose	SQLAlchemy or Tortoise ORM


from sqlalchemy import Column, Integer, String, ForeignKey, Index
from database import Base

class ChatLog(Base):
    __tablename__ = 'chat_logs'

    id = Column(Integer, primary_key=True)
    application_id = Column(Integer, ForeignKey("applications.id"))
    message = Column(String)

    __table_args__ = (
        Index("idx_chatlogs_application_id", "application_id"),  # üëà index defined here
    )



def upgrade():
    op.create_index('idx_chatlogs_application_id', 'chat_logs', ['application_id'])

def downgrade():
    op.drop_index('idx_chatlogs_application_id', table_name='chat_logs')



from sqlalchemy import create_engine

engine = create_engine(DB_URL)
with engine.connect() as conn:
    conn.execute("CREATE INDEX IF NOT EXISTS idx_chatlogs_application_id ON chat_logs(application_id)")



Index Naming Conventions (Best Practice)
Index Name	Target Field(s)
idx_<table>_<column>	Single column index
idx_<table>_<col1>_<col2>	Composite index



Summary: How to Create Index in Backend
Method	How to Do It	When to Use
Raw SQL	CREATE INDEX ...	Quick CLI or manual setup
SQLAlchemy ORM	__table_args__ = (Index(...),)	Auto-index with model
Alembic Migration	op.create_index(...)	Production-safe upgrades
Programmatically in Code	conn.execute("CREATE INDEX ...")	One-time setup via script

State Management for Browser Refresh 
------------------------------------
To persist state across refreshes or browser restarts, you need persistent storage like:

Storage Option	Description	Survives Refresh?
Local Storage	localStorage.setItem()	‚úÖ Yes
Session Storage	sessionStorage.setItem()	‚úÖ Yes (per tab)
Cookies	document.cookie	‚úÖ Yes
IndexedDB	For structured, large data	‚úÖ Yes
Redux Persist	Saves Redux store to persistent storage	‚úÖ Yes

Not Survive 
function Counter() {
  const [count, setCount] = React.useState(0);

  return (
    <button onClick={() => setCount(count + 1)}>
      Count: {count}
    </button>
  );
}

Survive
function Counter() {
  const [count, setCount] = React.useState(() => {
    const saved = localStorage.getItem('count');
    return saved ? JSON.parse(saved) : 0;
  });

  React.useEffect(() => {
    localStorage.setItem('count', JSON.stringify(count));
  }, [count]);

  return (
    <button onClick={() => setCount(count + 1)}>
      Count: {count}
    </button>
  );
}



FrontEnd Interview Preparation 
------------------------------
Must-Know Topics:
Scopes (var, let, const)
Closures, hoisting
Promises, async/await, event loop
this keyword, arrow functions
Array methods: map, filter, reduce, find
Object destructuring, spread/rest
ES6+ features (e.g., optional chaining ?., nullish coalescing ??)
Deep vs shallow copy
Type coercion and comparisons
Debounce vs throttle

Must-Know Concepts:
JSX and rendering logic
Functional components
useState, useEffect, useRef, useMemo, useCallback
Props vs state
Lifting state up
React Router (navigation and route params)
Controlled vs uncontrolled components
Form handling
Conditional rendering
Error boundaries (basic)
Keys in lists and their importance
Why does React need keys in a list? What happens if you use index?


TypeScript is expected in most mid-to-senior frontend roles now.

Must-Know Topics:
Type annotations: variables, functions, props
Interfaces vs types
Generics (basic)
Union types, optional types
Enums
Type narrowing, type guards
any, unknown, never, void


Component Design and Architecture
Reusable components (button, modal, form, etc.)
Props drilling vs context
Folder structure
Separation of concerns (e.g., logic vs UI)

State Management
useState, useReducer
Context API (lightweight global state)
Redux / Zustand / Jotai (know at least one if asked)

API Integration
Fetch / Axios
useEffect for calling APIs
Handling loading/error/success states
Optional: React Query or SWR

Basic HTML & CSS Knowledge
Semantic HTML
Flexbox & Grid
Responsiveness (media queries)
CSS-in-JS (e.g., styled-components, Tailwind)
Optional: CSS modules, SASS


Testing (Basic)
Unit tests with Jest
Component testing with React Testing Library
Even if you don‚Äôt write full tests, know:
render, fireEvent, getByText, etc.
Why testing is useful in React

Tooling & Environment
Vite / Webpack / Create React App
ESLint, Prettier
npm/yarn, scripts
Git basics


Soft Skills & System Design (Optional but Valuable)
How do you handle component scaling?
How do you organize your React project?
How would you handle a shared state across deeply nested components?
What‚Äôs the most challenging bug you‚Äôve solved?


Live Coding Practice
Build a to-do list, form with validation, API data table
Solve a few problems on LeetCode (Easy) or Frontend Mentor
Review common DOM manipulation tasks


Area	Must Know
JavaScript	Closures, async, array methods, scope
React	useState, useEffect, props, routing
TypeScript	Interfaces, types, unions, generics (basic)
APIs	Fetch, async calls, error handling
Styling	Flexbox, responsive, basic CSS
Testing	Jest + RTL (basic usage)
Project Structure	Clean, modular, reusable components


UML 
---
UML stands for Unified Modeling Language.
It‚Äôs a visual language used to model, design, and describe software systems.

To visualize system structure and behavior
To document architecture clearly
To communicate design with developers, clients, and stakeholders
To help in planning, analysis, and documentation

1. Structural Diagrams ‚Äì Show what the system is made of
Diagram Type	Description
Class Diagram	Shows classes, attributes, and relationships
Component Diagram	Shows high-level system components/modules
Object Diagram	Snapshot of objects at runtime
Deployment Diagram	Shows hardware and network setup
Package Diagram	Organizes classes into packages


2. Behavioral Diagrams ‚Äì Show how the system behaves
Diagram Type	Description
Use Case Diagram	Shows user interactions (user stories)
Sequence Diagram	Shows message flow between components
Activity Diagram	Shows workflow or business logic
State Diagram	Shows states and transitions of a system or object


Example: Class Diagram (Most Common)
Let‚Äôs say you‚Äôre designing a chat application.

Class Diagram:

+------------------+
|     ChatLog      |
+------------------+
| - id: int        |
| - message: string|
| - timestamp: Date|
| - applicationId: int |
+------------------+

        ‚ñ≤
        |
        |
+------------------+
|   Application    |
+------------------+
| - id: int        |
| - customerName: string |
+------------------+

This shows:

Two classes (ChatLog, Application)

One-to-many relationship (Application has many ChatLogs)


Tools to Draw UML
Lucidchart
Draw.io
StarUML
PlantUML (code-based UML)
Microsoft Visio

What is UML?	A standard visual language for designing systems
Why use UML?	To visualize, communicate, and document design
Types of UML?	Structural (class, component) + Behavioral (use case, sequence)
Tools to draw?	Lucidchart, Draw.io, PlantUML, etc


Figma
-----
Figma is a browser-based design tool used for UI/UX design, prototyping, and collaborating on frontend interfaces.
Because frontend developers need to convert designs into real code ‚Äî and Figma is where designers usually create those designs

How Frontend Developers Use Figma
What Designers Do in Figma	What You Do as a Developer
Design UI (buttons, pages, layouts)	Look at the layout and implement it in code (HTML/CSS/React)
Choose fonts, colors, spacing, icons	Copy those styles into CSS
Create interactive prototypes	Understand behavior and flow
Organize components (buttons, forms)	Build reusable components
Share links to the design	Use "Inspect" to get details like font-size, padding, etc.


What You Can Do with a Figma File (As a Dev)
‚úÖ Inspect spacing, padding, and layout
‚úÖ Copy CSS styles directly
‚úÖ Download assets (SVGs, images, icons)
‚úÖ Understand how screens are connected
‚úÖ Get font, color, border-radius, etc.
‚úÖ Check responsive behavior (frame sizes)

Example Workflow
1. Designer gives you a Figma link
They say: "Here‚Äôs the UI design for the dashboard page."
2. You open it in browser
No need to install anything ‚Äî just click the link.
3. You click a button in Figma
You see:
Font: Roboto, 16px
Padding: 12px 24px
Color: #1D4ED8
Border-radius: 6px
4. You build it in code:
<button className="px-6 py-3 text-base bg-blue-600 rounded-md text-white">
  Submit
</button>

Bonus: Figma + Tailwind + React
If your team uses Tailwind CSS, you can often map Figma styles directly to Tailwind classes based on Figma measurements.

And if you're using component libraries (e.g., Material UI, Chakra), you can recreate Figma designs using prebuilt components.


Figma Is Collaborative
Multiple people can view/edit at once (like Google Docs)
Developers + designers can leave comments
Version history is built-in

Question	Answer
What is Figma?	A browser-based UI/UX design and prototyping tool
Who uses it?	Designers, developers, product teams
Do I design in it as a dev?	No ‚Äî you read, inspect, and extract styles/assets
Why is it important?	It helps you turn designs into accurate frontend code
What can I get from Figma?	Fonts, colors, spacing, icons, layout, and even CSS suggestions

LLM Orchestration
-----------------
Tool/Framework	Role in Orchestration
LangChain	Prompt chaining, agent creation, tool use
LlamaIndex	Indexing and retrieval for RAG
Semantic Kernel	Microsoft‚Äôs orchestration for AI workflows
CrewAI / AutoGen	Agent-based orchestration
OpenAI Functions	Let LLMs call tools & APIs

Prompt Management:
Dynamically generating and structuring prompts.
Using prompt templates and chaining them across tasks.

Tool Use / Tool Integration:
Letting the LLM use external tools or APIs (e.g. search engines, calculators, databases).
Frameworks like LangChain, LlamaIndex, and Semantic Kernel handle this.

Memory & Context Management:
Storing and retrieving conversation history, long-term memory, or user data.
Avoiding LLM context window limitations.

Agent Management:
Using LLMs to create autonomous agents that can plan, decide, and act.
Orchestrating how these agents interact with one another or with humans.

Workflow Control / Task Planning:
Structuring tasks into sequences (e.g. first get data ‚Üí then analyze ‚Üí then report).
Handling branching logic, retries, or human-in-the-loop steps.

Data Augmented Generation (RAG):
Combining the LLM with real-time or external knowledge sources.
Retrieval-Augmented Generation is a common orchestration technique.


Scalability: Enables building full applications (not just chatbots).
Robustness: Manages edge cases, failures, and retries.
Interactivity: Makes LLMs work with tools, APIs, and users dynamically.
Customization: Allows tailoring responses to business or user-specific needs.


Contextlib
1.The contextlib module in Python provides utilities for working with context managers, especially in more flexible or advanced ways
2.Context managers are most commonly seen using the with statement, which ensures that certain setup and teardown operations are handled automatically
 with open("file.txt") as f:
      data = f.read()
   automatically opens and closes file, even if the error occurs that's the power of context managers 
3.@asynccontextmanager is like a context manager but for asynchronous code using async with
4.It lets you define async setup and teardown code around a block ‚Äî perfect for managing resources in FastAPI's app lifecycle.

5.Lifespan -> @asynccontextmanager
async def lifespan(_: FastAPI) -> AsyncIterator[None]:
This function will be run when the FastAPI app starts and stops.
The underscore _ means you‚Äôre not using the app instance passed in.
It yields None because we don‚Äôt return any special context value.
6.In a context manager (sync or async), the yield splits the function into two phases:
Setup phase (before yield)
This runs before the with or FastAPI app starts.
Teardown phase (after yield)
This runs after the with block exits, or when the app is shutting down.
7.So, yield is not returning a value here. It‚Äôs acting as a separator between setup and cleanup logic.
8.[ setup code ]  ‚Üí  yield (run app)  ‚Üí  [ cleanup code ]


Alembic 
-------
Check the Database
sqlite3 app/database.db
.tables
.exit

First-Time Setup (if database and Alembic config not set up yet)
alembic init alembic

Edit alembic.ini
sqlalchemy.url = sqlite:///app/database.db

alembic/env.py
from app.models import application, document, borrower
from sqlmodel import SQLModel

target_metadata = SQLModel.metadata

If you haven't already created the migration file:
alembic revision --autogenerate -m "Create tables"

Apply the migration to the database:
alembic upgrade head

Now your app/database.db file should be created with all the necessary tables.

Check if the alembic_version is there 
sqlite3 app/database.db ".tables"
If you see a table called alembic_version, like this:
alembic_version  application  borrower  document


# Optional: check what version the DB is at
alembic current

# Ensure DB is up-to-date (safe to re-run)
alembic upgrade head

# Run your app
fastapi dev app/main.py


Multiple Migration files 
------------------------
Multiple migration files were created in parallel (e.g., via alembic revision --autogenerate) without merging.

Use Alembic to create a merge file:
alembic merge -m "Merge heads" <rev1> <rev2>
alembic merge -m "Merge multiple heads" 477127da8ed3 fda4008df833

This will create the new version 
alembic/versions/xxxx_merge_heads.py

alembic upgrade head

After the Fix
Only one head will remain.
Future alembic revision will extend from the merged head.

Caution
Do not delete migration files manually.
If working in a team, make sure everyone rebases or pulls latest Alembic heads before creating new revisions.


To Check the migration history
alembic history --verbose


Two Migration Scenario
Branch 1
b325ffedf54b_created_tables.py
Parent: <base>
This was the first migration created ‚Äî from scratch.
Tables were defined here initially.
fda4008df833_added_column_ra_rr_risk_analysis.py
Parent: b325ffedf54b
This is a follow-up migration that added new columns related to risk analysis.
This file continues the lineage of Branch 1.
‚úÖ Valid migration chain: <base> ‚Üí b325ffedf54b ‚Üí fda4008df833

üü® Branch 2 (conflicting)
477127da8ed3_create_tables.py
Parent: <base>
This was created independently (also from <base>)
This did not continue from the previous migrations; instead, it's like a new branch.

Option 2: (Destructive) ‚Äî Clean Reset (if migrations are broken)
# Delete app/database.db
rm app/database.db

# Delete alembic/versions/*
rm alembic/versions/*.py

# Recreate single migration
alembic revision --autogenerate -m "Initial unified schema"
alembic upgrade head

Adding New Columns 
alembic revision --autogenerate -m "Add CreditScore model / Add rating to Borrower"
alembic/versions/abcd1234_add_creditscore_model.py
Inside, Alembic will detect schema changes based on the difference between:
Your current model definition (SQLModel.metadata)
The latest DB schema (tracked in alembic_version)

Review the migration file
def upgrade():
    op.add_column('borrower', sa.Column('rating', sa.String(), nullable=True))

def downgrade():
    op.drop_column('borrower', 'rating')

Apply the migration
alembic upgrade head


See current DB version	alembic current
See all migrations history	alembic history
Undo last migration	alembic downgrade -1
Recreate a fresh migration	alembic revision --autogenerate -m "..."
Reset DB (dangerous)	Delete DB + re-apply all migrations

Pitfall	Solution
Forgetting to run --autogenerate	Always generate a revision after model change
Editing DB manually	Avoid manual changes, use migrations
Skipping alembic upgrade head	Always apply migration before running app
Having multiple heads again	Don't create revisions in parallel branches

Enterprise Agent Settings
-------------------------
Value if Right 
Probability of Success 
Cost if it is wrong 
[P*V - (1-P)*C > Cost]*N of Running the Agent Put it in the Production 

High Problem - High Value 
Legal Space   - Lawyers & Research 
Finance Space - Research & Summarization 

RAG 5 Seconds- Older Schoool Question Answering Solution 
Deep Research - 10 Minutes - 
Cursor - 30 Seconds, inline autocomplete may some chat question answering there 
Claude Code 2 Hours - 7 Different Ambient Agents that run in the background 

Focusing on areas or verticals that provide value, 
Reshift the UI/UX interaction pattern - 

Probability of Success 
 - Uncontrollable agents 
 - Make Parts of your agents more deterministic 
 - Predictablity, Controllablity over what steps actually happen inside the agents 
     Prompting the Agent to do that great 
 - Workflow Like things in enterprise like things where you need more controllability, more predictability 
 - High Perceived error bars 
 - Observability and Evals - LangSmith 
Cost if Wrong 
 - Outsized effect in people's mind right row 
 - Make it easy to reverse - Easy to reverse changes that agent makes 

UI/UX tricks that people are doing and that successful agents have to kind of like just make this a non-issue 

Workflow and Agents 
* Agentic System - Parts of an agentic system are sometimes looping calling a tool 
* Multi Agent Architecture - After Agent finishes it will call the agent B, is that the workflow ? is that an agent ? 
                                                                                             middle ground 
* 







Resources 
---------
1.In the context of FastAPI (or any server application), resources are things your application uses to do its job ‚Äî and they often need to be initialized and then cleaned up properly.
‚úÖ Examples of Resources:
Resource Type	Description
Machine Learning Models	Models loaded into memory for inference.
Database Connections	Connections to PostgreSQL, MongoDB, Redis, etc.
Files / File Handles	Temporary files, open logs, images, etc.
Network Connections	APIs, WebSockets, message queues, etc.
Thread Pools / Workers	Background task runners, queues, schedulers.
GPU Memory / RAM	Especially for ML or graphics-heavy applications.
2.Because:
They can be expensive to initialize (like loading a model or opening a DB).
They can leak memory or cause crashes if not cleaned up.
You only want to do setup once, not per request.

Phase	What Happens
Setup	Initialize or allocate the resource.
Use	Use the resource to serve incoming requests.
Cleanup	Release memory, close files or DB connections when the app shuts down.

3.When your app connects to a database (like PostgreSQL, MySQL, MongoDB, etc.), it consumes multiple system and network-level resources
Resource	Explanation
TCP socket	A network connection between your app and the DB server
File descriptors	Operating system resources to manage open sockets
Memory	For query buffers, connection pools, and active result sets
Database server resources	Each connection consumes CPU and memory on the database server side too
Authentication tokens	Many DBs track and authenticate each active session

Let‚Äôs say your API gets 100 requests per second. If you open and close a DB connection on every request, you are:
Wasting time ‚Äî Creating a connection is slow.
Burning resources ‚Äî Each connection uses memory, sockets, CPU.
Risking DB overload ‚Äî DB servers have limits on how many connections they allow.
Missing optimization ‚Äî You can't reuse open connections


Key Points Have to Address 
1) Intially Worked as the Software Developer 
   Facilitate the Settlement & Payment System 
   Testing - Unit Testing, UAT Testing, 
   Release Mangement 
   Production Support Root Cause Analysis 
   Interacting with Client 
So I'm Proficient with Complete Software Development Lifecycle SDLC and BFSI Domain Knowledge 

2) I have Crossed Skilled from scracth in AI/ML Technologies and then got opportunities to Work as a AI Engineer 
  So I'm currently working in Developing the Agentic RAG System, The Usecase is to do the end-end to analysis & assessment for Loan Approval Process for institutional borrowers
so here my contribution is 
    in Data Engineering
       LLM Orchestration 
       LLM Application Testing 

3) These are my skillsets I have in GenAI tech 

i would like to do Research Every day to get up to date with AI Technologies 
4) and my strength is I'm good at Mathematically understanding the Artifical Intellgience, So Could able to contribute more and optimize and provide the Good Strategies in use of AI Technologies 

LLM Evaluation and Evaluation Metrics 
Azure AI Foundry 
Azure Function 
Agentic Course Recap 
GenAI Stack 
Programming Questions 


Coding Question
---------------
1.sorted(x,key=) -> Done
2. from collections import OrderedDict     -> Done
dicts = OrderedDict({"siva":"ra","Siva":"daj"})
dicts = OrderedDict([("siva","raj"),("dha","Siv"),("si","ra")])
dicts.move_to_end("siva")
print(dicts)
3. zip   --> Done
4. enumerate --> Done
5. [expression for item in iterable if condition]  --> Done 
6. Filter = list(filter(lambda,list)) - filter(None,list) -> Done
7. Map = list(map(lambda,list) 
8. Reduce = reduce(lambda x, y: x + y, numbers) 
            reduce(lambda x, y: x if x > y else y, numbers)
            reduce(lambda x, y: x + y, numbers, 10)
9. a = defaultdict(int)
       defaultdict(list) 
       defaultdict(lambda: "Not Found")
10. __slot__ -> avoid memory usage and speed up the attribute access, we can't add the attribut outside the class 
11. class Person:
    __slots__ = ['name', 'age']  # only these attributes are allowed

    def __init__(self, name, age):
        self.name = name
        self.age = age

p = Person("Alice", 30)
print(p.name)  # Alice
print(p.__slots__)  # ['name', 'age']
12.enum 
from enum import Enum

class Color(Enum):
    RED = 1
    GREEN = 2
    BLUE = 3
13.# Access members
print(Color.RED)          # Color.RED
print(Color.RED.name)     # 'RED'
print(Color.RED.value)    # 1

# Comparison
print(Color.RED == Color.RED)   # True
print(Color.RED == Color.GREEN) # False

# Iterating through members
for color in Color:
    print(color.name, color.value)
14.nums = list(map(int, input("Enter numbers: ").strip().split()))
15.class MyClass:
    class_var = 0

    def __init__(self):
        MyClass.class_var += 1

    @classmethod
    def get_instance_count(cls):
        return cls.class_var

class Person:
    def __init__(self, name):
        self.name = name

    @classmethod
    def from_string(cls, data):
        name = data.strip()
        return cls(name)

p = Person.from_string(" Alice ")
print(p.name)  # Alice

16. from functools import lru_cache

@lru_cache(maxsize=3)
def fetch_data(x):
    print(f"Fetching {x}...")
    return x * x

fetch_data(2)
fetch_data(3)
fetch_data(4)
fetch_data(2)  # This won't trigger the print because 2 is cached
fetch_data(5)  # Evicts 3 (Least Recently Used if maxsize=3)



from collections import OrderedDict

class LRUCache:
    def __init__(self, capacity: int):
        self.cache = OrderedDict()
        self.capacity = capacity

    def get(self, key):
        if key not in self.cache:
            return -1
        self.cache.move_to_end(key)  # mark as recently used
        return self.cache[key]

    def put(self, key, value):
        if key in self.cache:
            self.cache.move_to_end(key)
        self.cache[key] = value
        if len(self.cache) > self.capacity:
            self.cache.popitem(last=False)  # remove least recently used



1. LeetCode - Two Sum  - 1
     num_map = {}
     for i, num in enumerate(nums):
           complement = target - num 
           if complement in num_map:
              return [num_map[complement],i]  
           num_map[num] = i 

2. LeetCode - Contains Duplicate - 217
a = [1, 2, 3]
if len(a) == len(set(a)):
    print("False")
else:
    print("True")

3. LeetCode ---> Intersection of Two Arrays   --> 350  
from collections import Counter

def intersect(nums1, nums2):
    counts = Counter(nums1)  # Step 1
    result = []

    for num in nums2:  # Step 2
        if counts[num] > 0:  # Step 3
            result.append(num)
            counts[num] -= 1  # Step 4

    return result

4. LeetCode - Valid Anagram - 242 

5. LeetCode - Group Anagram - 49 
Hash_map and sorted - defaultdict
defaultdict(int,str,set,dict) 


6. Leetcode - Subset - distinct integer - powerset - 78
   Backtracking / DFS
   Use recursion to include or exclude each element.
a = [1,2,3]

results = [[]]
for i in a:
    print(results)
    results = results + [curr + [i] for curr in results]
    print(results)
print(results)






1. Storing , and after that checking that if present or not
2. Removal of list in if condition, not in the for loop 
3. Two Pointer Concept i and j alone 
4. from collections import Counter 
5. from collections import OrderedDict 
6. from collections import defaultdict 
7. sorted(,key=) will not work for list 






set --> add()



Major Difference B/w LangGraph/CrewAI/AutoGen
LangGraph ---> Design Style -- Deterministic or semi-Deterministic graph flows ---> Orchestrating tasks with dependencies or branching logic 
Stateful ---> Branching Logic B/w agent 
Finite State Machines and conditional transitions 
Eg: Document Review Pipeline, 

CrewAI --> distinct roles, that collaborate on a task, 
Desgin Style - Declarative , they figure out how to work together 

AutoGen --> Conversational agent Orchestration, Agents interact via messages in a dialogue loop, like slack thread 
Message-Passing Architecture 
It emphasizes modularity, decoupling, and asynchronous or synchronous communication between agents.
Central or Decentralized Coordination:
A central orchestrator may route messages (centralized).
Or agents may broadcast or subscribe to messages (decentralized/pub-sub).

Communication via Messages:
Agents don‚Äôt call each other directly.
They send structured messages (e.g., JSON, protocol buffers) through a shared bus or coordinator.

Interoperability:
Makes it easier to integrate new tools, APIs, or models without tightly coupling them.

Why Use Message Passing in Agentic Systems?
Agentic systems often need:
Flexible multi-agent collaboration.
Dynamic task delegation and reasoning.
Interpretable workflows.
Message passing enables this, especially for complex tasks that require planning, tool use, and memory.
Think of message passing as a team of specialists (agents) emailing each other tasks and results. Contrast that with a single boss micromanaging everyone by directly telling each person what to do and waiting for a response (function calls).


Feature	Message Passing	Monolithic / Function Call-Based
Modularity	High ‚Äî components loosely coupled	Low ‚Äî components tightly coupled
Scalability	High ‚Äî easy to add/replace agents	Low ‚Äî harder to scale modularly
Communication	Explicit via messages	Implicit via direct calls
Debugging	Easier (message logs)	Harder (trace deep call stacks)
Parallelism	Easier (agents work concurrently)	Harder (synchronous by default)
Examples	LangGraph, OpenDevin	Early AutoGPT, traditional scripts



üîÅ Message Passing Architecture in Agentic Frameworks
A message passing architecture is a communication model where agents or components exchange structured messages to perform tasks collaboratively. It emphasizes modularity, decoupling, and asynchronous or synchronous communication between agents.

‚úÖ Key Characteristics:
Modular Agents:
Each agent performs a specific function (e.g., planner, executor, memory).
Agents can be independently developed and maintained.
Communication via Messages:
Agents don‚Äôt call each other directly.
They send structured messages (e.g., JSON, protocol buffers) through a shared bus or coordinator.
Central or Decentralized Coordination:
A central orchestrator may route messages (centralized).
Or agents may broadcast or subscribe to messages (decentralized/pub-sub).
Interoperability:
Makes it easier to integrate new tools, APIs, or models without tightly coupling them.
Traceability & Debugging:
Every action can be traced through logs of message exchanges.

üìå Examples in Agentic Systems:
AutoGPT (to some extent): Task decomposition and tool execution steps are serialized and passed.
LangGraph: Nodes (agents/tools) communicate via messages passed along graph edges.
OpenAI's Function Calling with Agents: Messages between the planner and executor (via function calls and outputs).










 










































