LangChain - Course -1
from langchain.prompts import ChatPromptTemplate
from langchain.chat_models import ChatOpenAI
from langchain.schema.output_parser import StrOutputParser
from langchain.vectorstores import DocArrayInMemorySearch
from langchain.schema.runnable import RunnableMap
from langchain.utils.openai_functions import convert_pydantic_to_openai_function
from typing import List
from pydantic import BaseModel, Field
from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser
from typing import Optional
from langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser
from langchain.output_parsers.openai_functions import JsonKeyOutputFunctionsParser
from langchain.document_loaders import WebBaseLoader
from langchain.document_loaders import PlaywrightURLLoader
from langchain.document_loaders import SeleniumURLLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema.runnable import RunnableLambda
Chapter - 1
1) Routing - Tool selection and routing using LangChain tools and LLM function calling
2) LCEL - 
3) Function Definition by Pydantic 
4) Function Binding by two methods 
5) Using Function for Tagging 
6) extraction_chain = prompt | extraction_model | JsonKeyOutputFunctionsParser(key_name="people")  ---> Parse Based on Only Particular key
7) WebBaseLoader 


Code 
1.response = openai.ChatCompletion.create(
    # OpenAI Updates: As of June 2024, we are now using the GPT-3.5-Turbo model
    model="gpt-3.5-turbo",
    messages=messages,
    functions=functions
)
2.response = openai.ChatCompletion.create(
    # OpenAI Updates: As of June 2024, we are now using the GPT-3.5-Turbo model
    model="gpt-3.5-turbo",
    messages=messages,
    functions=functions,
    function_call="auto",
)
3.response = openai.ChatCompletion.create(
    # OpenAI Updates: As of June 2024, we are now using the GPT-3.5-Turbo model
    model="gpt-3.5-turbo",
    messages=messages,
    functions=functions,
    function_call="none",
)
4.response = openai.ChatCompletion.create(
    # OpenAI Updates: As of June 2024, we are now using the GPT-3.5-Turbo model
    model="gpt-3.5-turbo",
    messages=messages,
    functions=functions,
    function_call={"name": "get_current_weather"},
)
5.Prompt - 
prompt = ChatPromptTemplate.from_template(
    "tell me a short joke about {topic}"
)
6.Output Parser - output_parser = StrOutputParser()
7.Chain
  chain = prompt | model | output_parser
  chain.invoke({"topic": "bears"})
8.Document storing for sample - vectorstore = DocArrayInMemorySearch.from_texts(
    ["harrison worked at kensho", "bears like to eat honey"],
    embedding=OpenAIEmbeddings()
)
  retriever = vectorstore.as_retriever()
retriever.get_relevant_documents("where did harrison work?")
9.RunnableMap - chain = RunnableMap({
    "context": lambda x: retriever.get_relevant_documents(x["question"]),
    "question": lambda x: x["question"]
}) | prompt | model | output_parser

10 Runnable - 
       Logging
       Fallback 
       Parallelsim 
       Streaming Support 
11.Runnable Map 
      chain = RunnableMap({
    "context": lambda x: retriever.get_relevant_documents(x["question"]),
    "question": lambda x: x["question"]
}) | prompt | model | output_parser

12.chain.invoke({"question": "where did harrison work?"})

13. Binding the Functions 
prompt = ChatPromptTemplate.from_messages(
    [
        ("human", "{input}")
    ]
)
model = ChatOpenAI(temperature=0).bind(functions=functions)
runnable = prompt | model

14. Fallback - final_chain = simple_chain.with_fallbacks([chain])   --> [chain] is advanced chain 
15. Structured Output 
          - get the string from LLM - chain = model | StrOutputParser() | json.loads

16. Interface 
        invoke    ainvoke
        batch     abatch
        stream    astream 
17. Function Binding and Function is giving at invoking 
18. Pydantic - creating OpenAI Function Description, 
19. Pydantic - Optional Usage 
        from typing import Optional
class Person(BaseModel):
    """Information about a person."""
    name: str = Field(description="person's name")
    age: Optional[int] = Field(description="person's age")
20. Runnable Lambda - prep = RunnableLambda(
    lambda x: [{"input": doc} for doc in text_splitter.split_text(x)]
)


--------
Langchain Course - 3 - LangChain for LLM Application Development
1.Apply LLMs to your proprietary data to build personal assistants and specialized chatbots
2.Use agents, chained calls, and memories to expand your use of LLMs
3.Models, Prompts and Parsers: calling LLMs, providing prompts and parsing the response
4.Memories for LLMs: memories to store conversations and manage limited context space
5.Chains: creating sequences of operations
6.Agents: explore the powerful emerging development of LLM as reasoning agents.



Agentic AI Links 
https://lilianweng.github.io/posts/2023-06-23-agent/

OpenAI API Key 
https://platform.openai.com/account/api-keys




